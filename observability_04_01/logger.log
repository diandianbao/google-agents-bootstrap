http_handler.py:678 DEBUG:Using AiohttpTransport...
http_handler.py:736 DEBUG:Creating AiohttpTransport...
http_handler.py:746 DEBUG:NEW SESSION: Creating new ClientSession (no shared session provided)
_trace.py:47 DEBUG:connect_tcp.started host='raw.githubusercontent.com' port=443 local_address=None timeout=5 socket_options=None
_trace.py:47 DEBUG:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x113c45160>
_trace.py:47 DEBUG:start_tls.started ssl_context=<ssl.SSLContext object at 0x1139abbf0> server_hostname='raw.githubusercontent.com' timeout=5
_trace.py:47 DEBUG:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11399a990>
_trace.py:47 DEBUG:send_request_headers.started request=<Request [b'GET']>
_trace.py:47 DEBUG:send_request_headers.complete
_trace.py:47 DEBUG:send_request_body.started request=<Request [b'GET']>
_trace.py:47 DEBUG:send_request_body.complete
_trace.py:47 DEBUG:receive_response_headers.started request=<Request [b'GET']>
_trace.py:47 DEBUG:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Connection', b'keep-alive'), (b'Content-Length', b'50093'), (b'Cache-Control', b'max-age=300'), (b'Content-Security-Policy', b"default-src 'none'; style-src 'unsafe-inline'; sandbox"), (b'Content-Type', b'text/plain; charset=utf-8'), (b'ETag', b'W/"b800016f302a965c1145243ccb12614719190f1b87ae94c17d9a2973b0d95bbb"'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'X-Content-Type-Options', b'nosniff'), (b'X-Frame-Options', b'deny'), (b'X-XSS-Protection', b'1; mode=block'), (b'X-GitHub-Request-Id', b'CF66:16629B:519F8:CB488:6924DCC8'), (b'Content-Encoding', b'gzip'), (b'Accept-Ranges', b'bytes'), (b'Date', b'Tue, 25 Nov 2025 07:08:45 GMT'), (b'Via', b'1.1 varnish'), (b'X-Served-By', b'cache-nrt-rjtf7700024-NRT'), (b'X-Cache', b'HIT'), (b'X-Cache-Hits', b'14'), (b'X-Timer', b'S1764054525.416914,VS0,VE0'), (b'Vary', b'Authorization,Accept-Encoding'), (b'Access-Control-Allow-Origin', b'*'), (b'Cross-Origin-Resource-Policy', b'cross-origin'), (b'X-Fastly-Request-ID', b'5d50f35f7a3e14cc3762d89c01e1128389ffad2d'), (b'Expires', b'Tue, 25 Nov 2025 07:13:45 GMT'), (b'Source-Age', b'100')])
_trace.py:47 DEBUG:receive_response_body.started request=<Request [b'GET']>
_trace.py:47 DEBUG:receive_response_body.complete
_trace.py:47 DEBUG:response_closed.started
_trace.py:47 DEBUG:response_closed.complete
_trace.py:47 DEBUG:close.started
_trace.py:47 DEBUG:close.complete
litellm_logging.py:186 DEBUG:[Non-Blocking] Unable to import GenericAPILogger - LiteLLM Enterprise Feature - No module named 'litellm_enterprise'
http_handler.py:678 DEBUG:Using AiohttpTransport...
http_handler.py:736 DEBUG:Creating AiohttpTransport...
http_handler.py:746 DEBUG:NEW SESSION: Creating new ClientSession (no shared session provided)
http_handler.py:678 DEBUG:Using AiohttpTransport...
http_handler.py:736 DEBUG:Creating AiohttpTransport...
http_handler.py:746 DEBUG:NEW SESSION: Creating new ClientSession (no shared session provided)
http_handler.py:678 DEBUG:Using AiohttpTransport...
http_handler.py:736 DEBUG:Creating AiohttpTransport...
http_handler.py:746 DEBUG:NEW SESSION: Creating new ClientSession (no shared session provided)
plugin_manager.py:104 INFO:Plugin 'logging_plugin' registered.
selector_events.py:64 DEBUG:Using selector: KqueueSelector
lite_llm.py:1162 DEBUG:
LLM Request:
-----------------------------------------------------------
System Instruction:
Your task is to find research papers and count them. 

    You MUST ALWAYS follow these steps:
    1) Find research papers on the user provided topic using the 'google_search_agent'. 
    2) Then, pass the papers to 'count_papers' tool to count the number of papers returned.
    3) Return both the list of research papers and the total number of papers.
    

You are an agent. Your internal name is "research_paper_finder_agent".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Find recent papers on quantum computing"}],"role":"user"}
-----------------------------------------------------------
Functions:
google_search_agent: {'request': {'type': <Type.STRING: 'STRING'>}} -> None
count_papers: {'papers': {'type': <Type.STRING: 'STRING'>}} -> None
-----------------------------------------------------------

utils.py:375 DEBUG:

utils.py:375 DEBUG:[92mRequest to litellm:[0m
utils.py:375 DEBUG:[92mlitellm.acompletion(model='qwen3:30b', messages=[{'role': 'developer', 'content': 'Your task is to find research papers and count them. \n\n    You MUST ALWAYS follow these steps:\n    1) Find research papers on the user provided topic using the \'google_search_agent\'. \n    2) Then, pass the papers to \'count_papers\' tool to count the number of papers returned.\n    3) Return both the list of research papers and the total number of papers.\n    \n\nYou are an agent. Your internal name is "research_paper_finder_agent".'}, {'role': 'user', 'content': 'Find recent papers on quantum computing'}], tools=[{'type': 'function', 'function': {'name': 'google_search_agent', 'description': 'Searches for information using Google search', 'parameters': {'type': 'object', 'properties': {'request': {'type': 'string'}}, 'required': ['request']}}}, {'type': 'function', 'function': {'name': 'count_papers', 'description': '\nThis function counts the number of papers in a list of strings.\nArgs:\n  papers: A list of strings, where each string is a research paper.\nReturns:\n  The number of papers in the list.\n', 'parameters': {'type': 'object', 'properties': {'papers': {'type': 'string'}}, 'required': ['papers']}}}], response_format=None, api_base='http://localhost:11434/v1', custom_llm_provider='openai', api_key='ollama')[0m
utils.py:375 DEBUG:

litellm_logging.py:488 DEBUG:self.optional_params: {}
utils.py:375 DEBUG:ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None
main.py:501 DEBUG:üîÑ NO SHARED SESSION: acompletion called without shared_session
base_utils.py:219 DEBUG:Translating developer role to system role for non-OpenAI providers.
utils.py:3421 INFO:
LiteLLM completion() model= qwen3:30b; provider = openai
utils.py:3424 DEBUG:
LiteLLM: Params passed to completion() {'model': 'qwen3:30b', 'functions': None, 'function_call': None, 'temperature': None, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': [{'type': 'function', 'function': {'name': 'google_search_agent', 'description': 'Searches for information using Google search', 'parameters': {'type': 'object', 'properties': {'request': {'type': 'string'}}, 'required': ['request']}}}, {'type': 'function', 'function': {'name': 'count_papers', 'description': '\nThis function counts the number of papers in a list of strings.\nArgs:\n  papers: A list of strings, where each string is a research paper.\nReturns:\n  The number of papers in the list.\n', 'parameters': {'type': 'object', 'properties': {'papers': {'type': 'string'}}, 'required': ['papers']}}}], 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': 'Your task is to find research papers and count them. \n\n    You MUST ALWAYS follow these steps:\n    1) Find research papers on the user provided topic using the \'google_search_agent\'. \n    2) Then, pass the papers to \'count_papers\' tool to count the number of papers returned.\n    3) Return both the list of research papers and the total number of papers.\n    \n\nYou are an agent. Your internal name is "research_paper_finder_agent".'}, {'role': 'user', 'content': 'Find recent papers on quantum computing'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
utils.py:3427 DEBUG:
LiteLLM: Non-Default params passed to completion() {'tools': [{'type': 'function', 'function': {'name': 'google_search_agent', 'description': 'Searches for information using Google search', 'parameters': {'type': 'object', 'properties': {'request': {'type': 'string'}}, 'required': ['request']}}}, {'type': 'function', 'function': {'name': 'count_papers', 'description': '\nThis function counts the number of papers in a list of strings.\nArgs:\n  papers: A list of strings, where each string is a research paper.\nReturns:\n  The number of papers in the list.\n', 'parameters': {'type': 'object', 'properties': {'papers': {'type': 'string'}}, 'required': ['papers']}}}]}
utils.py:375 DEBUG:Final returned optional params: {'tools': [{'type': 'function', 'function': {'name': 'google_search_agent', 'description': 'Searches for information using Google search', 'parameters': {'type': 'object', 'properties': {'request': {'type': 'string'}}, 'required': ['request']}}}, {'type': 'function', 'function': {'name': 'count_papers', 'description': '\nThis function counts the number of papers in a list of strings.\nArgs:\n  papers: A list of strings, where each string is a research paper.\nReturns:\n  The number of papers in the list.\n', 'parameters': {'type': 'object', 'properties': {'papers': {'type': 'string'}}, 'required': ['papers']}}}], 'extra_body': {}}
litellm_logging.py:488 DEBUG:self.optional_params: {'tools': [{'type': 'function', 'function': {'name': 'google_search_agent', 'description': 'Searches for information using Google search', 'parameters': {'type': 'object', 'properties': {'request': {'type': 'string'}}, 'required': ['request']}}}, {'type': 'function', 'function': {'name': 'count_papers', 'description': '\nThis function counts the number of papers in a list of strings.\nArgs:\n  papers: A list of strings, where each string is a research paper.\nReturns:\n  The number of papers in the list.\n', 'parameters': {'type': 'object', 'properties': {'papers': {'type': 'string'}}, 'required': ['papers']}}}], 'extra_body': {}}
utils.py:4822 DEBUG:checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3:30b', 'combined_model_name': 'openai/qwen3:30b', 'stripped_model_name': 'qwen3:30b', 'combined_stripped_model_name': 'openai/qwen3:30b', 'custom_llm_provider': 'openai'}
utils.py:5064 DEBUG:Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
main.py:924 DEBUG:Error getting model info: This model isn't mapped yet. model=qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
http_handler.py:678 DEBUG:Using AiohttpTransport...
http_handler.py:736 DEBUG:Creating AiohttpTransport...
http_handler.py:746 DEBUG:NEW SESSION: Creating new ClientSession (no shared session provided)
litellm_logging.py:961 DEBUG:[92m

POST Request Sent from LiteLLM:
curl -X POST \
http://localhost:11434/v1/ \
-H 'Authorization: Be****ma' \
-d '{'model': 'qwen3:30b', 'messages': [{'role': 'system', 'content': 'Your task is to find research papers and count them. \n\n    You MUST ALWAYS follow these steps:\n    1) Find research papers on the user provided topic using the \'google_search_agent\'. \n    2) Then, pass the papers to \'count_papers\' tool to count the number of papers returned.\n    3) Return both the list of research papers and the total number of papers.\n    \n\nYou are an agent. Your internal name is "research_paper_finder_agent".'}, {'role': 'user', 'content': 'Find recent papers on quantum computing'}], 'tools': [{'type': 'function', 'function': {'name': 'google_search_agent', 'description': 'Searches for information using Google search', 'parameters': {'type': 'object', 'properties': {'request': {'type': 'string'}}, 'required': ['request']}}}, {'type': 'function', 'function': {'name': 'count_papers', 'description': '\nThis function counts the number of papers in a list of strings.\nArgs:\n  papers: A list of strings, where each string is a research paper.\nReturns:\n  The number of papers in the list.\n', 'parameters': {'type': 'object', 'properties': {'papers': {'type': 'string'}}, 'required': ['papers']}}}], 'extra_body': {}}'
[0m

_base_client.py:482 DEBUG:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-3bf7fb74-a2df-492f-b3d6-1cb7b24391dd', 'json_data': {'messages': [{'role': 'system', 'content': 'Your task is to find research papers and count them. \n\n    You MUST ALWAYS follow these steps:\n    1) Find research papers on the user provided topic using the \'google_search_agent\'. \n    2) Then, pass the papers to \'count_papers\' tool to count the number of papers returned.\n    3) Return both the list of research papers and the total number of papers.\n    \n\nYou are an agent. Your internal name is "research_paper_finder_agent".'}, {'role': 'user', 'content': 'Find recent papers on quantum computing'}], 'model': 'qwen3:30b', 'tools': [{'type': 'function', 'function': {'name': 'google_search_agent', 'description': 'Searches for information using Google search', 'parameters': {'type': 'object', 'properties': {'request': {'type': 'string'}}, 'required': ['request']}}}, {'type': 'function', 'function': {'name': 'count_papers', 'description': '\nThis function counts the number of papers in a list of strings.\nArgs:\n  papers: A list of strings, where each string is a research paper.\nReturns:\n  The number of papers in the list.\n', 'parameters': {'type': 'object', 'properties': {'papers': {'type': 'string'}}, 'required': ['papers']}}}]}, 'extra_json': {}}
_base_client.py:1525 DEBUG:Sending HTTP Request: POST http://localhost:11434/v1/chat/completions
_base_client.py:1563 DEBUG:HTTP Response: POST http://localhost:11434/v1/chat/completions "200 OK" Headers({'content-type': 'application/json', 'date': 'Tue, 25 Nov 2025 07:09:03 GMT', 'transfer-encoding': 'chunked'})
_base_client.py:1571 DEBUG:request_id: None
litellm_logging.py:1034 DEBUG:RAW RESPONSE:
{"id": "chatcmpl-912", "choices": [{"finish_reason": "tool_calls", "index": 0, "logprobs": null, "message": {"content": "", "refusal": null, "role": "assistant", "annotations": null, "audio": null, "function_call": null, "tool_calls": [{"id": "call_451ak1zq", "function": {"arguments": "{\"request\":\"quantum computing\"}", "name": "google_search_agent"}, "type": "function", "index": 0}], "reasoning": "Okay, the user wants me to find recent research papers on quantum computing. Let me break this down.\n\nFirst, I need to use the google_search_agent to look up recent papers. The topic is \"quantum computing,\" so I'll input that as the request. The function requires a 'request' parameter, which should be the search term. So the first step is to call google_search_agent with \"quantum computing\" as the request.\n\nWait, the user specified \"recent,\" but the search agent might not handle the time aspect. Maybe the agent's default is to return recent results. I'll just use the keyword.\n\nNext, once I get the list of papers from the search, I need to pass that list to the count_papers function. The count_papers function expects a list of strings, but the tool's parameter is a string. Hmm, maybe the papers are provided as a string list, but the tool's parameter is a string. Wait, the parameters for count_papers has \"papers\" as a string. Wait, the description says \"papers: A list of strings, where each string is a research paper.\" But the parameter is a string. That seems conflicting. Maybe it's a typo, and the input should be a string representation of a list. But the user told me to pass the papers to count_papers, so perhaps the actual list will be a string like [\"Paper1\", \"Paper2\"], and the function expects that.\n\nBut as per the instructions, I should first call google_search_agent, get the results, then use count_papers with the list. However, in this case, since I'm simulating, I'll have to generate the tool calls. So first tool call is google_search_agent with the topic. Then, assume the search returns some papers, then call count_papers with that list.\n\nSo step 1: Use google_search_agent to search \"quantum computing\".\n\nWait, the user says \"Find recent papers on quantum computing\"\u2014so the request should be \"recent papers on quantum computing\" or just \"quantum computing\". Let me check the function. The request parameter is a string, so I'll put \"quantum computing\" as the search term.\n\nSo first tool call: google_search_agent with request \"quantum computing\".\n\nThen, after that returns some papers (as a list), pass that to count_papers. But since I don't have actual data, I'll have to simulate the tool responses.\n\nWait, but the instructions say to return the tool calls in the specified format. So for each tool call, output a tool_call XML with the name and arguments. So first, I need to make the first tool call.\n\nThe correct JSON for the tool call would be the name \"google_search_agent\" and arguments with \"request\": \"quantum computing\".\n\nSo in the tool_call tags, it's:\n\n{\"name\": \"google_search_agent\", \"arguments\": {\"request\": \"quantum computing\"}}\n\nThen, after that, the system would presumably return some papers, and then I need to call count_papers. But since this is a simulation, I should only make the first call now, right? Because the user expects me to make the first tool call as per the steps.\n\nWait, the user's instructions say to first find the papers using the search agent, then pass them to count_papers. So the assistant's response should include the first tool call. The next step (counting) comes after receiving the search results, but since this is the first response, I can only do the first call.\n\nSo the correct action now is to output the tool call for google_search_agent with request \"quantum computing\".\n"}}], "created": 1764054543, "model": "qwen3:30b", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_ollama", "usage": {"completion_tokens": 776, "prompt_tokens": 330, "total_tokens": 1106, "completion_tokens_details": null, "prompt_tokens_details": null}}


litellm_logging.py:2928 DEBUG:Filtered callbacks: []
cost_calculator.py:797 DEBUG:selected model name for cost calculation: openai/qwen3:30b
utils.py:4822 DEBUG:checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3:30b', 'combined_model_name': 'openai/qwen3:30b', 'stripped_model_name': 'qwen3:30b', 'combined_stripped_model_name': 'openai/qwen3:30b', 'custom_llm_provider': 'openai'}
utils.py:5064 DEBUG:Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
cost_calculator.py:1099 DEBUG:litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/qwen3:30b - This model isn't mapped yet. model=openai/qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
cost_calculator.py:797 DEBUG:selected model name for cost calculation: qwen3:30b
utils.py:4822 DEBUG:checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3:30b', 'combined_model_name': 'openai/qwen3:30b', 'stripped_model_name': 'qwen3:30b', 'combined_stripped_model_name': 'openai/qwen3:30b', 'custom_llm_provider': 'openai'}
utils.py:5064 DEBUG:Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
cost_calculator.py:1099 DEBUG:litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=qwen3:30b - This model isn't mapped yet. model=qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
litellm_logging.py:1328 DEBUG:response_cost_failure_debug_information: {'error_str': "This model isn't mapped yet. model=qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.", 'traceback_str': 'Traceback (most recent call last):\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/utils.py", line 4911, in _get_model_info_helper\n    raise ValueError(\n        "This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json"\n    )\nValueError: This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/litellm_core_utils/litellm_logging.py", line 1310, in _response_cost_calculator\n    response_cost = litellm.response_cost_calculator(\n        **response_cost_calculator_kwargs\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1220, in response_cost_calculator\n    raise e\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1203, in response_cost_calculator\n    response_cost = completion_cost(\n        completion_response=response_object,\n    ...<11 lines>...\n        service_tier=service_tier,\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1112, in completion_cost\n    raise e\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1105, in completion_cost\n    raise e\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1044, in completion_cost\n    ) = cost_per_token(\n        ~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<16 lines>...\n        response=completion_response,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 362, in cost_per_token\n    return openai_cost_per_token(\n        model=model, usage=usage_block, service_tier=service_tier\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/llms/openai/cost_calculation.py", line 33, in cost_per_token\n    return generic_cost_per_token(\n        model=model, usage=usage, custom_llm_provider="openai", service_tier=service_tier\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/litellm_core_utils/llm_cost_calc/utils.py", line 514, in generic_cost_per_token\n    model_info = get_model_info(model=model, custom_llm_provider=custom_llm_provider)\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/utils.py", line 5149, in get_model_info\n    _model_info = _get_model_info_helper(\n        model=model,\n        custom_llm_provider=custom_llm_provider,\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/utils.py", line 5067, in _get_model_info_helper\n    raise Exception(\n    ...<3 lines>...\n    )\nException: This model isn\'t mapped yet. model=qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n', 'model': 'qwen3:30b', 'cache_hit': False, 'custom_llm_provider': 'openai', 'base_model': None, 'call_type': 'acompletion', 'custom_pricing': False}
utils.py:375 DEBUG:Async Wrapper: Completed Call, calling async_success_handler: <bound method Logging.async_success_handler of <litellm.litellm_core_utils.litellm_logging.Logging object at 0x121f4f770>>
litellm_logging.py:2928 DEBUG:Filtered callbacks: []
plugin_manager.py:104 INFO:Plugin 'logging_plugin' registered.
lite_llm.py:1162 DEBUG:
LLM Request:
-----------------------------------------------------------
System Instruction:
Use the google_search tool to find information on the given topic. Return the raw search results.
    If the user asks for a list of papers, then give them the list of research papers you found and not the summary.

You are an agent. Your internal name is "google_search_agent". The description about you is "Searches for information using Google search".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"quantum computing"}],"role":"user"}
-----------------------------------------------------------
Functions:
serpapi_search: {'query': {'type': <Type.STRING: 'STRING'>}, 'num_results': {'default': 5, 'type': <Type.INTEGER: 'INTEGER'>}} -> None
-----------------------------------------------------------

utils.py:375 DEBUG:

utils.py:375 DEBUG:[92mRequest to litellm:[0m
utils.py:375 DEBUG:[92mlitellm.acompletion(model='qwen3:30b', messages=[{'role': 'developer', 'content': 'Use the google_search tool to find information on the given topic. Return the raw search results.\n    If the user asks for a list of papers, then give them the list of research papers you found and not the summary.\n\nYou are an agent. Your internal name is "google_search_agent". The description about you is "Searches for information using Google search".'}, {'role': 'user', 'content': 'quantum computing'}], tools=[{'type': 'function', 'function': {'name': 'serpapi_search', 'description': '\nSerpAPIÊêúÁ¥¢Â∑•ÂÖ∑ÂáΩÊï∞\n\nArgs:\n    query: ÊêúÁ¥¢ÂÖ≥ÈîÆËØç\n    num_results: ËøîÂõûÁªìÊûúÊï∞Èáè\n\nReturns:\n    Dict: ÊêúÁ¥¢ÁªìÊûú\n    {\n    "title": ...,\n     "url": ...,\n     "snippet": ...,\n     "source": "GoogleÊêúÁ¥¢",\n     "position": ...\n    }\n\n', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}, 'num_results': {'default': 5, 'type': 'integer'}}, 'required': ['query']}}}], response_format=None, api_base='http://localhost:11434/v1', custom_llm_provider='openai', api_key='ollama')[0m
utils.py:375 DEBUG:

litellm_logging.py:488 DEBUG:self.optional_params: {}
utils.py:375 DEBUG:ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None
main.py:501 DEBUG:üîÑ NO SHARED SESSION: acompletion called without shared_session
base_utils.py:219 DEBUG:Translating developer role to system role for non-OpenAI providers.
utils.py:3421 INFO:
LiteLLM completion() model= qwen3:30b; provider = openai
utils.py:375 DEBUG:Logging Details LiteLLM-Async Success Call, cache_hit=None
utils.py:3424 DEBUG:
LiteLLM: Params passed to completion() {'model': 'qwen3:30b', 'functions': None, 'function_call': None, 'temperature': None, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': [{'type': 'function', 'function': {'name': 'serpapi_search', 'description': '\nSerpAPIÊêúÁ¥¢Â∑•ÂÖ∑ÂáΩÊï∞\n\nArgs:\n    query: ÊêúÁ¥¢ÂÖ≥ÈîÆËØç\n    num_results: ËøîÂõûÁªìÊûúÊï∞Èáè\n\nReturns:\n    Dict: ÊêúÁ¥¢ÁªìÊûú\n    {\n    "title": ...,\n     "url": ...,\n     "snippet": ...,\n     "source": "GoogleÊêúÁ¥¢",\n     "position": ...\n    }\n\n', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}, 'num_results': {'default': 5, 'type': 'integer'}}, 'required': ['query']}}}], 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': 'Use the google_search tool to find information on the given topic. Return the raw search results.\n    If the user asks for a list of papers, then give them the list of research papers you found and not the summary.\n\nYou are an agent. Your internal name is "google_search_agent". The description about you is "Searches for information using Google search".'}, {'role': 'user', 'content': 'quantum computing'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
utils.py:4822 DEBUG:checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3:30b', 'combined_model_name': 'openai/qwen3:30b', 'stripped_model_name': 'qwen3:30b', 'combined_stripped_model_name': 'openai/qwen3:30b', 'custom_llm_provider': 'openai'}
utils.py:3427 DEBUG:
LiteLLM: Non-Default params passed to completion() {'tools': [{'type': 'function', 'function': {'name': 'serpapi_search', 'description': '\nSerpAPIÊêúÁ¥¢Â∑•ÂÖ∑ÂáΩÊï∞\n\nArgs:\n    query: ÊêúÁ¥¢ÂÖ≥ÈîÆËØç\n    num_results: ËøîÂõûÁªìÊûúÊï∞Èáè\n\nReturns:\n    Dict: ÊêúÁ¥¢ÁªìÊûú\n    {\n    "title": ...,\n     "url": ...,\n     "snippet": ...,\n     "source": "GoogleÊêúÁ¥¢",\n     "position": ...\n    }\n\n', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}, 'num_results': {'default': 5, 'type': 'integer'}}, 'required': ['query']}}}]}
utils.py:5064 DEBUG:Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
utils.py:375 DEBUG:Final returned optional params: {'tools': [{'type': 'function', 'function': {'name': 'serpapi_search', 'description': '\nSerpAPIÊêúÁ¥¢Â∑•ÂÖ∑ÂáΩÊï∞\n\nArgs:\n    query: ÊêúÁ¥¢ÂÖ≥ÈîÆËØç\n    num_results: ËøîÂõûÁªìÊûúÊï∞Èáè\n\nReturns:\n    Dict: ÊêúÁ¥¢ÁªìÊûú\n    {\n    "title": ...,\n     "url": ...,\n     "snippet": ...,\n     "source": "GoogleÊêúÁ¥¢",\n     "position": ...\n    }\n\n', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}, 'num_results': {'default': 5, 'type': 'integer'}}, 'required': ['query']}}}], 'extra_body': {}}
litellm_logging.py:4180 DEBUG:Model=qwen3:30b is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload
litellm_logging.py:488 DEBUG:self.optional_params: {'tools': [{'type': 'function', 'function': {'name': 'serpapi_search', 'description': '\nSerpAPIÊêúÁ¥¢Â∑•ÂÖ∑ÂáΩÊï∞\n\nArgs:\n    query: ÊêúÁ¥¢ÂÖ≥ÈîÆËØç\n    num_results: ËøîÂõûÁªìÊûúÊï∞Èáè\n\nReturns:\n    Dict: ÊêúÁ¥¢ÁªìÊûú\n    {\n    "title": ...,\n     "url": ...,\n     "snippet": ...,\n     "source": "GoogleÊêúÁ¥¢",\n     "position": ...\n    }\n\n', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}, 'num_results': {'default': 5, 'type': 'integer'}}, 'required': ['query']}}}], 'extra_body': {}}
utils.py:375 DEBUG:Async success callbacks: Got a complete streaming response
utils.py:4822 DEBUG:checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3:30b', 'combined_model_name': 'openai/qwen3:30b', 'stripped_model_name': 'qwen3:30b', 'combined_stripped_model_name': 'openai/qwen3:30b', 'custom_llm_provider': 'openai'}
cost_calculator.py:797 DEBUG:selected model name for cost calculation: openai/qwen3:30b
utils.py:5064 DEBUG:Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
utils.py:4822 DEBUG:checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3:30b', 'combined_model_name': 'openai/qwen3:30b', 'stripped_model_name': 'qwen3:30b', 'combined_stripped_model_name': 'openai/qwen3:30b', 'custom_llm_provider': 'openai'}
main.py:924 DEBUG:Error getting model info: This model isn't mapped yet. model=qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
utils.py:5064 DEBUG:Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
cost_calculator.py:1099 DEBUG:litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/qwen3:30b - This model isn't mapped yet. model=openai/qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
cost_calculator.py:797 DEBUG:selected model name for cost calculation: qwen3:30b
utils.py:4822 DEBUG:checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3:30b', 'combined_model_name': 'openai/qwen3:30b', 'stripped_model_name': 'qwen3:30b', 'combined_stripped_model_name': 'openai/qwen3:30b', 'custom_llm_provider': 'openai'}
utils.py:5064 DEBUG:Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
cost_calculator.py:1099 DEBUG:litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=qwen3:30b - This model isn't mapped yet. model=qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
litellm_logging.py:1328 DEBUG:response_cost_failure_debug_information: {'error_str': "This model isn't mapped yet. model=qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.", 'traceback_str': 'Traceback (most recent call last):\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/utils.py", line 4911, in _get_model_info_helper\n    raise ValueError(\n        "This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json"\n    )\nValueError: This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/litellm_core_utils/litellm_logging.py", line 1310, in _response_cost_calculator\n    response_cost = litellm.response_cost_calculator(\n        **response_cost_calculator_kwargs\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1220, in response_cost_calculator\n    raise e\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1203, in response_cost_calculator\n    response_cost = completion_cost(\n        completion_response=response_object,\n    ...<11 lines>...\n        service_tier=service_tier,\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1112, in completion_cost\n    raise e\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1105, in completion_cost\n    raise e\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1044, in completion_cost\n    ) = cost_per_token(\n        ~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<16 lines>...\n        response=completion_response,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 362, in cost_per_token\n    return openai_cost_per_token(\n        model=model, usage=usage_block, service_tier=service_tier\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/llms/openai/cost_calculation.py", line 33, in cost_per_token\n    return generic_cost_per_token(\n        model=model, usage=usage, custom_llm_provider="openai", service_tier=service_tier\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/litellm_core_utils/llm_cost_calc/utils.py", line 514, in generic_cost_per_token\n    model_info = get_model_info(model=model, custom_llm_provider=custom_llm_provider)\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/utils.py", line 5149, in get_model_info\n    _model_info = _get_model_info_helper(\n        model=model,\n        custom_llm_provider=custom_llm_provider,\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/utils.py", line 5067, in _get_model_info_helper\n    raise Exception(\n    ...<3 lines>...\n    )\nException: This model isn\'t mapped yet. model=qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n', 'model': 'qwen3:30b', 'cache_hit': None, 'custom_llm_provider': 'openai', 'base_model': None, 'call_type': 'acompletion', 'custom_pricing': False}
litellm_logging.py:2265 DEBUG:Model=qwen3:30b; cost=None
utils.py:4822 DEBUG:checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3:30b', 'combined_model_name': 'openai/qwen3:30b', 'stripped_model_name': 'qwen3:30b', 'combined_stripped_model_name': 'openai/qwen3:30b', 'custom_llm_provider': 'openai'}
utils.py:5064 DEBUG:Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
litellm_logging.py:4180 DEBUG:Model=qwen3:30b is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload
litellm_logging.py:961 DEBUG:[92m

POST Request Sent from LiteLLM:
curl -X POST \
http://localhost:11434/v1/ \
-H 'Authorization: Be****ma' \
-d '{'model': 'qwen3:30b', 'messages': [{'role': 'system', 'content': 'Use the google_search tool to find information on the given topic. Return the raw search results.\n    If the user asks for a list of papers, then give them the list of research papers you found and not the summary.\n\nYou are an agent. Your internal name is "google_search_agent". The description about you is "Searches for information using Google search".'}, {'role': 'user', 'content': 'quantum computing'}], 'tools': [{'type': 'function', 'function': {'name': 'serpapi_search', 'description': '\nSerpAPIÊêúÁ¥¢Â∑•ÂÖ∑ÂáΩÊï∞\n\nArgs:\n    query: ÊêúÁ¥¢ÂÖ≥ÈîÆËØç\n    num_results: ËøîÂõûÁªìÊûúÊï∞Èáè\n\nReturns:\n    Dict: ÊêúÁ¥¢ÁªìÊûú\n    {\n    "title": ...,\n     "url": ...,\n     "snippet": ...,\n     "source": "GoogleÊêúÁ¥¢",\n     "position": ...\n    }\n\n', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}, 'num_results': {'default': 5, 'type': 'integer'}}, 'required': ['query']}}}], 'extra_body': {}}'
[0m

_base_client.py:482 DEBUG:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-580ab778-8da6-4e95-a54a-c47bc8210516', 'json_data': {'messages': [{'role': 'system', 'content': 'Use the google_search tool to find information on the given topic. Return the raw search results.\n    If the user asks for a list of papers, then give them the list of research papers you found and not the summary.\n\nYou are an agent. Your internal name is "google_search_agent". The description about you is "Searches for information using Google search".'}, {'role': 'user', 'content': 'quantum computing'}], 'model': 'qwen3:30b', 'tools': [{'type': 'function', 'function': {'name': 'serpapi_search', 'description': '\nSerpAPIÊêúÁ¥¢Â∑•ÂÖ∑ÂáΩÊï∞\n\nArgs:\n    query: ÊêúÁ¥¢ÂÖ≥ÈîÆËØç\n    num_results: ËøîÂõûÁªìÊûúÊï∞Èáè\n\nReturns:\n    Dict: ÊêúÁ¥¢ÁªìÊûú\n    {\n    "title": ...,\n     "url": ...,\n     "snippet": ...,\n     "source": "GoogleÊêúÁ¥¢",\n     "position": ...\n    }\n\n', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}, 'num_results': {'default': 5, 'type': 'integer'}}, 'required': ['query']}}}]}, 'extra_json': {}}
_base_client.py:1525 DEBUG:Sending HTTP Request: POST http://localhost:11434/v1/chat/completions
_base_client.py:1563 DEBUG:HTTP Response: POST http://localhost:11434/v1/chat/completions "200 OK" Headers({'content-type': 'application/json', 'date': 'Tue, 25 Nov 2025 07:09:08 GMT', 'transfer-encoding': 'chunked'})
_base_client.py:1571 DEBUG:request_id: None
litellm_logging.py:1034 DEBUG:RAW RESPONSE:
{"id": "chatcmpl-133", "choices": [{"finish_reason": "tool_calls", "index": 0, "logprobs": null, "message": {"content": "", "refusal": null, "role": "assistant", "annotations": null, "audio": null, "function_call": null, "tool_calls": [{"id": "call_1qwhjlpx", "function": {"arguments": "{\"num_results\":5,\"query\":\"quantum computing\"}", "name": "serpapi_search"}, "type": "function", "index": 0}], "reasoning": "Okay, the user asked for \"quantum computing\". Let me figure out what they need. The instructions say if they want a list of papers, return the raw search results. But the user just wrote \"quantum computing\", so I should probably search for general information.\n\nFirst, I need to use the search tool. The function name is serpapi_search. The required parameter is query, so I'll set query to \"quantum computing\". The user didn't specify number of results, so maybe default to a standard number, like 5. Wait, the parameters say num_results is an integer, but it's not required. Wait, the parameters show num_results is a property in the function's parameters, but it's not required. The required field is just query. So I should include num_results as 5 to get a reasonable number of results.\n\nWait, the description says if the user asks for papers, give the list. But they didn't ask for papers, just the topic. So I should search for general info, not specifically academic papers. But the tool is to get search results. So I'll proceed to call serpapi_search with query \"quantum computing\" and num_results 5.\n\nWait, check the parameters again. The parameters have num_results as an integer, optional. So I'll set it to 5. Let me make sure the function is correct. The example shows that the search function returns title, url, snippet, source, position.\n\nSo the tool call should be serpapi_search with these parameters. Let me structure the JSON correctly. The arguments should include query and num_results.\n\nSo the tool_call JSON will have name \"serpapi_search\" and arguments {\"query\": \"quantum computing\", \"num_results\": 5}.\n"}}], "created": 1764054548, "model": "qwen3:30b", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_ollama", "usage": {"completion_tokens": 396, "prompt_tokens": 297, "total_tokens": 693, "completion_tokens_details": null, "prompt_tokens_details": null}}


litellm_logging.py:2928 DEBUG:Filtered callbacks: []
cost_calculator.py:797 DEBUG:selected model name for cost calculation: openai/qwen3:30b
utils.py:4822 DEBUG:checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3:30b', 'combined_model_name': 'openai/qwen3:30b', 'stripped_model_name': 'qwen3:30b', 'combined_stripped_model_name': 'openai/qwen3:30b', 'custom_llm_provider': 'openai'}
utils.py:5064 DEBUG:Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
cost_calculator.py:1099 DEBUG:litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/qwen3:30b - This model isn't mapped yet. model=openai/qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
cost_calculator.py:797 DEBUG:selected model name for cost calculation: qwen3:30b
utils.py:4822 DEBUG:checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3:30b', 'combined_model_name': 'openai/qwen3:30b', 'stripped_model_name': 'qwen3:30b', 'combined_stripped_model_name': 'openai/qwen3:30b', 'custom_llm_provider': 'openai'}
utils.py:5064 DEBUG:Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
cost_calculator.py:1099 DEBUG:litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=qwen3:30b - This model isn't mapped yet. model=qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
litellm_logging.py:1328 DEBUG:response_cost_failure_debug_information: {'error_str': "This model isn't mapped yet. model=qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.", 'traceback_str': 'Traceback (most recent call last):\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/utils.py", line 4911, in _get_model_info_helper\n    raise ValueError(\n        "This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json"\n    )\nValueError: This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/litellm_core_utils/litellm_logging.py", line 1310, in _response_cost_calculator\n    response_cost = litellm.response_cost_calculator(\n        **response_cost_calculator_kwargs\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1220, in response_cost_calculator\n    raise e\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1203, in response_cost_calculator\n    response_cost = completion_cost(\n        completion_response=response_object,\n    ...<11 lines>...\n        service_tier=service_tier,\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1112, in completion_cost\n    raise e\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1105, in completion_cost\n    raise e\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1044, in completion_cost\n    ) = cost_per_token(\n        ~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<16 lines>...\n        response=completion_response,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 362, in cost_per_token\n    return openai_cost_per_token(\n        model=model, usage=usage_block, service_tier=service_tier\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/llms/openai/cost_calculation.py", line 33, in cost_per_token\n    return generic_cost_per_token(\n        model=model, usage=usage, custom_llm_provider="openai", service_tier=service_tier\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/litellm_core_utils/llm_cost_calc/utils.py", line 514, in generic_cost_per_token\n    model_info = get_model_info(model=model, custom_llm_provider=custom_llm_provider)\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/utils.py", line 5149, in get_model_info\n    _model_info = _get_model_info_helper(\n        model=model,\n        custom_llm_provider=custom_llm_provider,\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/utils.py", line 5067, in _get_model_info_helper\n    raise Exception(\n    ...<3 lines>...\n    )\nException: This model isn\'t mapped yet. model=qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n', 'model': 'qwen3:30b', 'cache_hit': False, 'custom_llm_provider': 'openai', 'base_model': None, 'call_type': 'acompletion', 'custom_pricing': False}
utils.py:375 DEBUG:Async Wrapper: Completed Call, calling async_success_handler: <bound method Logging.async_success_handler of <litellm.litellm_core_utils.litellm_logging.Logging object at 0x122c18050>>
litellm_logging.py:2928 DEBUG:Filtered callbacks: []
utils.py:375 DEBUG:Logging Details LiteLLM-Async Success Call, cache_hit=None
utils.py:4822 DEBUG:checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3:30b', 'combined_model_name': 'openai/qwen3:30b', 'stripped_model_name': 'qwen3:30b', 'combined_stripped_model_name': 'openai/qwen3:30b', 'custom_llm_provider': 'openai'}
utils.py:5064 DEBUG:Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
litellm_logging.py:4180 DEBUG:Model=qwen3:30b is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload
utils.py:375 DEBUG:Async success callbacks: Got a complete streaming response
cost_calculator.py:797 DEBUG:selected model name for cost calculation: openai/qwen3:30b
utils.py:4822 DEBUG:checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3:30b', 'combined_model_name': 'openai/qwen3:30b', 'stripped_model_name': 'qwen3:30b', 'combined_stripped_model_name': 'openai/qwen3:30b', 'custom_llm_provider': 'openai'}
utils.py:5064 DEBUG:Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
cost_calculator.py:1099 DEBUG:litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/qwen3:30b - This model isn't mapped yet. model=openai/qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
cost_calculator.py:797 DEBUG:selected model name for cost calculation: qwen3:30b
utils.py:4822 DEBUG:checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3:30b', 'combined_model_name': 'openai/qwen3:30b', 'stripped_model_name': 'qwen3:30b', 'combined_stripped_model_name': 'openai/qwen3:30b', 'custom_llm_provider': 'openai'}
utils.py:5064 DEBUG:Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
cost_calculator.py:1099 DEBUG:litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=qwen3:30b - This model isn't mapped yet. model=qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
litellm_logging.py:1328 DEBUG:response_cost_failure_debug_information: {'error_str': "This model isn't mapped yet. model=qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.", 'traceback_str': 'Traceback (most recent call last):\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/utils.py", line 4911, in _get_model_info_helper\n    raise ValueError(\n        "This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json"\n    )\nValueError: This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/litellm_core_utils/litellm_logging.py", line 1310, in _response_cost_calculator\n    response_cost = litellm.response_cost_calculator(\n        **response_cost_calculator_kwargs\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1220, in response_cost_calculator\n    raise e\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1203, in response_cost_calculator\n    response_cost = completion_cost(\n        completion_response=response_object,\n    ...<11 lines>...\n        service_tier=service_tier,\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1112, in completion_cost\n    raise e\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1105, in completion_cost\n    raise e\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1044, in completion_cost\n    ) = cost_per_token(\n        ~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<16 lines>...\n        response=completion_response,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 362, in cost_per_token\n    return openai_cost_per_token(\n        model=model, usage=usage_block, service_tier=service_tier\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/llms/openai/cost_calculation.py", line 33, in cost_per_token\n    return generic_cost_per_token(\n        model=model, usage=usage, custom_llm_provider="openai", service_tier=service_tier\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/litellm_core_utils/llm_cost_calc/utils.py", line 514, in generic_cost_per_token\n    model_info = get_model_info(model=model, custom_llm_provider=custom_llm_provider)\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/utils.py", line 5149, in get_model_info\n    _model_info = _get_model_info_helper(\n        model=model,\n        custom_llm_provider=custom_llm_provider,\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/utils.py", line 5067, in _get_model_info_helper\n    raise Exception(\n    ...<3 lines>...\n    )\nException: This model isn\'t mapped yet. model=qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n', 'model': 'qwen3:30b', 'cache_hit': None, 'custom_llm_provider': 'openai', 'base_model': None, 'call_type': 'acompletion', 'custom_pricing': False}
litellm_logging.py:2265 DEBUG:Model=qwen3:30b; cost=None
utils.py:4822 DEBUG:checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3:30b', 'combined_model_name': 'openai/qwen3:30b', 'stripped_model_name': 'qwen3:30b', 'combined_stripped_model_name': 'openai/qwen3:30b', 'custom_llm_provider': 'openai'}
utils.py:5064 DEBUG:Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
litellm_logging.py:4180 DEBUG:Model=qwen3:30b is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload
lite_llm.py:1162 DEBUG:
LLM Request:
-----------------------------------------------------------
System Instruction:
Use the google_search tool to find information on the given topic. Return the raw search results.
    If the user asks for a list of papers, then give them the list of research papers you found and not the summary.

You are an agent. Your internal name is "google_search_agent". The description about you is "Searches for information using Google search".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"quantum computing"}],"role":"user"}
{"parts":[{"function_call":{"id":"call_1qwhjlpx","args":{"num_results":5,"query":"quantum computing"},"name":"serpapi_search"}}],"role":"model"}
{"parts":[{"function_response":{"id":"call_1qwhjlpx","name":"serpapi_search","response":{"status":"success","query":"quantum computing","results":[{"title":"ÂÖ≥‰∫é 'quantum computing' ÁöÑÊêúÁ¥¢ÁªìÊûú 1","url":"https://www.google.com/search?q=quantum+computing","snippet":"ËøôÊòØÂÖ≥‰∫é 'quantum computing' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 1„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ","source":"GoogleÊêúÁ¥¢","position":1},{"title":"ÂÖ≥‰∫é 'quantum computing' ÁöÑÊêúÁ¥¢ÁªìÊûú 2","url":"https://www.google.com/search?q=quantum+computing","snippet":"ËøôÊòØÂÖ≥‰∫é 'quantum computing' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 2„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ","source":"GoogleÊêúÁ¥¢","position":2},{"title":"ÂÖ≥‰∫é 'quantum computing' ÁöÑÊêúÁ¥¢ÁªìÊûú 3","url":"https://www.google.com/search?q=quantum+computing","snippet":"ËøôÊòØÂÖ≥‰∫é 'quantum computing' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 3„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ","source":"GoogleÊêúÁ¥¢","position":3},{"title":"ÂÖ≥‰∫é 'quantum computing' ÁöÑÊêúÁ¥¢ÁªìÊûú 4","url":"https://www.google.com/search?q=quantum+computing","snippet":"ËøôÊòØÂÖ≥‰∫é 'quantum computing' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 4„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ","source":"GoogleÊêúÁ¥¢","position":4},{"title":"ÂÖ≥‰∫é 'quantum computing' ÁöÑÊêúÁ¥¢ÁªìÊûú 5","url":"https://www.google.com/search?q=quantum+computing","snippet":"ËøôÊòØÂÖ≥‰∫é 'quantum computing' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 5„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ","source":"GoogleÊêúÁ¥¢","position":5}],"total_results":5,"source":"demo_mode","note":"ÂΩìÂâç‰ΩøÁî®ÊºîÁ§∫Ê®°ÂºèÔºåËØ∑ÈÖçÁΩÆSerpAPIÂØÜÈí•‰ª•Ëé∑ÂèñÁúüÂÆûÊêúÁ¥¢ÁªìÊûú"}}},{"text":"Handle the requests as specified in the System Instruction."}],"role":"user"}
-----------------------------------------------------------
Functions:
serpapi_search: {'query': {'type': <Type.STRING: 'STRING'>}, 'num_results': {'default': 5, 'type': <Type.INTEGER: 'INTEGER'>}} -> None
-----------------------------------------------------------

utils.py:375 DEBUG:

utils.py:375 DEBUG:[92mRequest to litellm:[0m
utils.py:375 DEBUG:[92mlitellm.acompletion(model='qwen3:30b', messages=[{'role': 'developer', 'content': 'Use the google_search tool to find information on the given topic. Return the raw search results.\n    If the user asks for a list of papers, then give them the list of research papers you found and not the summary.\n\nYou are an agent. Your internal name is "google_search_agent". The description about you is "Searches for information using Google search".'}, {'role': 'user', 'content': 'quantum computing'}, {'role': 'assistant', 'content': None, 'tool_calls': [{'type': 'function', 'id': 'call_1qwhjlpx', 'function': {'name': 'serpapi_search', 'arguments': '{"num_results": 5, "query": "quantum computing"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_1qwhjlpx', 'content': '{"status": "success", "query": "quantum computing", "results": [{"title": "ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 1", "url": "https://www.google.com/search?q=quantum+computing", "snippet": "ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 1„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ", "source": "GoogleÊêúÁ¥¢", "position": 1}, {"title": "ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 2", "url": "https://www.google.com/search?q=quantum+computing", "snippet": "ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 2„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ", "source": "GoogleÊêúÁ¥¢", "position": 2}, {"title": "ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 3", "url": "https://www.google.com/search?q=quantum+computing", "snippet": "ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 3„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ", "source": "GoogleÊêúÁ¥¢", "position": 3}, {"title": "ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 4", "url": "https://www.google.com/search?q=quantum+computing", "snippet": "ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 4„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ", "source": "GoogleÊêúÁ¥¢", "position": 4}, {"title": "ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 5", "url": "https://www.google.com/search?q=quantum+computing", "snippet": "ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 5„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ", "source": "GoogleÊêúÁ¥¢", "position": 5}], "total_results": 5, "source": "demo_mode", "note": "ÂΩìÂâç‰ΩøÁî®ÊºîÁ§∫Ê®°ÂºèÔºåËØ∑ÈÖçÁΩÆSerpAPIÂØÜÈí•‰ª•Ëé∑ÂèñÁúüÂÆûÊêúÁ¥¢ÁªìÊûú"}'}], tools=[{'type': 'function', 'function': {'name': 'serpapi_search', 'description': '\nSerpAPIÊêúÁ¥¢Â∑•ÂÖ∑ÂáΩÊï∞\n\nArgs:\n    query: ÊêúÁ¥¢ÂÖ≥ÈîÆËØç\n    num_results: ËøîÂõûÁªìÊûúÊï∞Èáè\n\nReturns:\n    Dict: ÊêúÁ¥¢ÁªìÊûú\n    {\n    "title": ...,\n     "url": ...,\n     "snippet": ...,\n     "source": "GoogleÊêúÁ¥¢",\n     "position": ...\n    }\n\n', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}, 'num_results': {'default': 5, 'type': 'integer'}}, 'required': ['query']}}}], response_format=None, api_base='http://localhost:11434/v1', custom_llm_provider='openai', api_key='ollama')[0m
utils.py:375 DEBUG:

litellm_logging.py:488 DEBUG:self.optional_params: {}
utils.py:375 DEBUG:ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None
main.py:501 DEBUG:üîÑ NO SHARED SESSION: acompletion called without shared_session
base_utils.py:219 DEBUG:Translating developer role to system role for non-OpenAI providers.
utils.py:3421 INFO:
LiteLLM completion() model= qwen3:30b; provider = openai
utils.py:3424 DEBUG:
LiteLLM: Params passed to completion() {'model': 'qwen3:30b', 'functions': None, 'function_call': None, 'temperature': None, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': [{'type': 'function', 'function': {'name': 'serpapi_search', 'description': '\nSerpAPIÊêúÁ¥¢Â∑•ÂÖ∑ÂáΩÊï∞\n\nArgs:\n    query: ÊêúÁ¥¢ÂÖ≥ÈîÆËØç\n    num_results: ËøîÂõûÁªìÊûúÊï∞Èáè\n\nReturns:\n    Dict: ÊêúÁ¥¢ÁªìÊûú\n    {\n    "title": ...,\n     "url": ...,\n     "snippet": ...,\n     "source": "GoogleÊêúÁ¥¢",\n     "position": ...\n    }\n\n', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}, 'num_results': {'default': 5, 'type': 'integer'}}, 'required': ['query']}}}], 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': 'Use the google_search tool to find information on the given topic. Return the raw search results.\n    If the user asks for a list of papers, then give them the list of research papers you found and not the summary.\n\nYou are an agent. Your internal name is "google_search_agent". The description about you is "Searches for information using Google search".'}, {'role': 'user', 'content': 'quantum computing'}, {'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_1qwhjlpx', 'function': {'name': 'serpapi_search', 'arguments': '{"num_results": 5, "query": "quantum computing"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_1qwhjlpx', 'content': '{"status": "success", "query": "quantum computing", "results": [{"title": "ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 1", "url": "https://www.google.com/search?q=quantum+computing", "snippet": "ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 1„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ", "source": "GoogleÊêúÁ¥¢", "position": 1}, {"title": "ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 2", "url": "https://www.google.com/search?q=quantum+computing", "snippet": "ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 2„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ", "source": "GoogleÊêúÁ¥¢", "position": 2}, {"title": "ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 3", "url": "https://www.google.com/search?q=quantum+computing", "snippet": "ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 3„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ", "source": "GoogleÊêúÁ¥¢", "position": 3}, {"title": "ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 4", "url": "https://www.google.com/search?q=quantum+computing", "snippet": "ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 4„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ", "source": "GoogleÊêúÁ¥¢", "position": 4}, {"title": "ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 5", "url": "https://www.google.com/search?q=quantum+computing", "snippet": "ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 5„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ", "source": "GoogleÊêúÁ¥¢", "position": 5}], "total_results": 5, "source": "demo_mode", "note": "ÂΩìÂâç‰ΩøÁî®ÊºîÁ§∫Ê®°ÂºèÔºåËØ∑ÈÖçÁΩÆSerpAPIÂØÜÈí•‰ª•Ëé∑ÂèñÁúüÂÆûÊêúÁ¥¢ÁªìÊûú"}'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
utils.py:3427 DEBUG:
LiteLLM: Non-Default params passed to completion() {'tools': [{'type': 'function', 'function': {'name': 'serpapi_search', 'description': '\nSerpAPIÊêúÁ¥¢Â∑•ÂÖ∑ÂáΩÊï∞\n\nArgs:\n    query: ÊêúÁ¥¢ÂÖ≥ÈîÆËØç\n    num_results: ËøîÂõûÁªìÊûúÊï∞Èáè\n\nReturns:\n    Dict: ÊêúÁ¥¢ÁªìÊûú\n    {\n    "title": ...,\n     "url": ...,\n     "snippet": ...,\n     "source": "GoogleÊêúÁ¥¢",\n     "position": ...\n    }\n\n', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}, 'num_results': {'default': 5, 'type': 'integer'}}, 'required': ['query']}}}]}
utils.py:375 DEBUG:Final returned optional params: {'tools': [{'type': 'function', 'function': {'name': 'serpapi_search', 'description': '\nSerpAPIÊêúÁ¥¢Â∑•ÂÖ∑ÂáΩÊï∞\n\nArgs:\n    query: ÊêúÁ¥¢ÂÖ≥ÈîÆËØç\n    num_results: ËøîÂõûÁªìÊûúÊï∞Èáè\n\nReturns:\n    Dict: ÊêúÁ¥¢ÁªìÊûú\n    {\n    "title": ...,\n     "url": ...,\n     "snippet": ...,\n     "source": "GoogleÊêúÁ¥¢",\n     "position": ...\n    }\n\n', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}, 'num_results': {'default': 5, 'type': 'integer'}}, 'required': ['query']}}}], 'extra_body': {}}
litellm_logging.py:488 DEBUG:self.optional_params: {'tools': [{'type': 'function', 'function': {'name': 'serpapi_search', 'description': '\nSerpAPIÊêúÁ¥¢Â∑•ÂÖ∑ÂáΩÊï∞\n\nArgs:\n    query: ÊêúÁ¥¢ÂÖ≥ÈîÆËØç\n    num_results: ËøîÂõûÁªìÊûúÊï∞Èáè\n\nReturns:\n    Dict: ÊêúÁ¥¢ÁªìÊûú\n    {\n    "title": ...,\n     "url": ...,\n     "snippet": ...,\n     "source": "GoogleÊêúÁ¥¢",\n     "position": ...\n    }\n\n', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}, 'num_results': {'default': 5, 'type': 'integer'}}, 'required': ['query']}}}], 'extra_body': {}}
utils.py:4822 DEBUG:checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3:30b', 'combined_model_name': 'openai/qwen3:30b', 'stripped_model_name': 'qwen3:30b', 'combined_stripped_model_name': 'openai/qwen3:30b', 'custom_llm_provider': 'openai'}
utils.py:5064 DEBUG:Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
main.py:924 DEBUG:Error getting model info: This model isn't mapped yet. model=qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
litellm_logging.py:961 DEBUG:[92m

POST Request Sent from LiteLLM:
curl -X POST \
http://localhost:11434/v1/ \
-H 'Authorization: Be****ma' \
-d '{'model': 'qwen3:30b', 'messages': [{'role': 'system', 'content': 'Use the google_search tool to find information on the given topic. Return the raw search results.\n    If the user asks for a list of papers, then give them the list of research papers you found and not the summary.\n\nYou are an agent. Your internal name is "google_search_agent". The description about you is "Searches for information using Google search".'}, {'role': 'user', 'content': 'quantum computing'}, {'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_1qwhjlpx', 'function': {'name': 'serpapi_search', 'arguments': '{"num_results": 5, "query": "quantum computing"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_1qwhjlpx', 'content': '{"status": "success", "query": "quantum computing", "results": [{"title": "ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 1", "url": "https://www.google.com/search?q=quantum+computing", "snippet": "ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 1„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ", "source": "GoogleÊêúÁ¥¢", "position": 1}, {"title": "ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 2", "url": "https://www.google.com/search?q=quantum+computing", "snippet": "ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 2„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ", "source": "GoogleÊêúÁ¥¢", "position": 2}, {"title": "ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 3", "url": "https://www.google.com/search?q=quantum+computing", "snippet": "ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 3„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ", "source": "GoogleÊêúÁ¥¢", "position": 3}, {"title": "ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 4", "url": "https://www.google.com/search?q=quantum+computing", "snippet": "ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 4„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ", "source": "GoogleÊêúÁ¥¢", "position": 4}, {"title": "ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 5", "url": "https://www.google.com/search?q=quantum+computing", "snippet": "ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 5„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ", "source": "GoogleÊêúÁ¥¢", "position": 5}], "total_results": 5, "source": "demo_mode", "note": "ÂΩìÂâç‰ΩøÁî®ÊºîÁ§∫Ê®°ÂºèÔºåËØ∑ÈÖçÁΩÆSerpAPIÂØÜÈí•‰ª•Ëé∑ÂèñÁúüÂÆûÊêúÁ¥¢ÁªìÊûú"}'}], 'tools': [{'type': 'function', 'function': {'name': 'serpapi_search', 'description': '\nSerpAPIÊêúÁ¥¢Â∑•ÂÖ∑ÂáΩÊï∞\n\nArgs:\n    query: ÊêúÁ¥¢ÂÖ≥ÈîÆËØç\n    num_results: ËøîÂõûÁªìÊûúÊï∞Èáè\n\nReturns:\n    Dict: ÊêúÁ¥¢ÁªìÊûú\n    {\n    "title": ...,\n     "url": ...,\n     "snippet": ...,\n     "source": "GoogleÊêúÁ¥¢",\n     "position": ...\n    }\n\n', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}, 'num_results': {'default': 5, 'type': 'integer'}}, 'required': ['query']}}}], 'extra_body': {}}'
[0m

_base_client.py:482 DEBUG:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-b11b2a97-ed48-4059-9f96-08aabb432b7c', 'json_data': {'messages': [{'role': 'system', 'content': 'Use the google_search tool to find information on the given topic. Return the raw search results.\n    If the user asks for a list of papers, then give them the list of research papers you found and not the summary.\n\nYou are an agent. Your internal name is "google_search_agent". The description about you is "Searches for information using Google search".'}, {'role': 'user', 'content': 'quantum computing'}, {'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_1qwhjlpx', 'function': {'name': 'serpapi_search', 'arguments': '{"num_results": 5, "query": "quantum computing"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_1qwhjlpx', 'content': '{"status": "success", "query": "quantum computing", "results": [{"title": "ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 1", "url": "https://www.google.com/search?q=quantum+computing", "snippet": "ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 1„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ", "source": "GoogleÊêúÁ¥¢", "position": 1}, {"title": "ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 2", "url": "https://www.google.com/search?q=quantum+computing", "snippet": "ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 2„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ", "source": "GoogleÊêúÁ¥¢", "position": 2}, {"title": "ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 3", "url": "https://www.google.com/search?q=quantum+computing", "snippet": "ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 3„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ", "source": "GoogleÊêúÁ¥¢", "position": 3}, {"title": "ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 4", "url": "https://www.google.com/search?q=quantum+computing", "snippet": "ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 4„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ", "source": "GoogleÊêúÁ¥¢", "position": 4}, {"title": "ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 5", "url": "https://www.google.com/search?q=quantum+computing", "snippet": "ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 5„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ", "source": "GoogleÊêúÁ¥¢", "position": 5}], "total_results": 5, "source": "demo_mode", "note": "ÂΩìÂâç‰ΩøÁî®ÊºîÁ§∫Ê®°ÂºèÔºåËØ∑ÈÖçÁΩÆSerpAPIÂØÜÈí•‰ª•Ëé∑ÂèñÁúüÂÆûÊêúÁ¥¢ÁªìÊûú"}'}], 'model': 'qwen3:30b', 'tools': [{'type': 'function', 'function': {'name': 'serpapi_search', 'description': '\nSerpAPIÊêúÁ¥¢Â∑•ÂÖ∑ÂáΩÊï∞\n\nArgs:\n    query: ÊêúÁ¥¢ÂÖ≥ÈîÆËØç\n    num_results: ËøîÂõûÁªìÊûúÊï∞Èáè\n\nReturns:\n    Dict: ÊêúÁ¥¢ÁªìÊûú\n    {\n    "title": ...,\n     "url": ...,\n     "snippet": ...,\n     "source": "GoogleÊêúÁ¥¢",\n     "position": ...\n    }\n\n', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}, 'num_results': {'default': 5, 'type': 'integer'}}, 'required': ['query']}}}]}, 'extra_json': {}}
_base_client.py:1525 DEBUG:Sending HTTP Request: POST http://localhost:11434/v1/chat/completions
_base_client.py:1563 DEBUG:HTTP Response: POST http://localhost:11434/v1/chat/completions "200 OK" Headers({'content-type': 'application/json', 'date': 'Tue, 25 Nov 2025 07:09:23 GMT', 'transfer-encoding': 'chunked'})
_base_client.py:1571 DEBUG:request_id: None
litellm_logging.py:1034 DEBUG:RAW RESPONSE:
{"id": "chatcmpl-240", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "The raw search results for \"quantum computing\" are as follows:\n\n1. **Title**: \u5173\u4e8e 'quantum computing' \u7684\u641c\u7d22\u7ed3\u679c 1  \n   **URL**: https://www.google.com/search?q=quantum+computing  \n   **Snippet**: \u8fd9\u662f\u5173\u4e8e 'quantum computing' \u7684\u8be6\u7ec6\u641c\u7d22\u7ed3\u679c\u6458\u8981 1\u3002\u5728\u5b9e\u9645\u4f7f\u7528\u4e2d\uff0c\u8fd9\u91cc\u4f1a\u663e\u793a\u901a\u8fc7SerpAPI\u83b7\u53d6\u7684\u771f\u5b9e\u641c\u7d22\u7ed3\u679c\u5185\u5bb9\u3002  \n   **Source**: Google\u641c\u7d22  \n   **Position**: 1  \n\n2. **Title**: \u5173\u4e8e 'quantum computing' \u7684\u641c\u7d22\u7ed3\u679c 2  \n   **URL**: https://www.google.com/search?q=quantum+computing  \n   **Snippet**: \u8fd9\u662f\u5173\u4e8e 'quantum computing' \u7684\u8be6\u7ec6\u641c\u7d22\u7ed3\u679c\u6458\u8981 2\u3002\u5728\u5b9e\u9645\u4f7f\u7528\u4e2d\uff0c\u8fd9\u91cc\u4f1a\u663e\u793a\u901a\u8fc7SerpAPI\u83b7\u53d6\u7684\u771f\u5b9e\u641c\u7d22\u7ed3\u679c\u5185\u5bb9\u3002  \n   **Source**: Google\u641c\u7d22  \n   **Position**: 2  \n\n3. **Title**: \u5173\u4e8e 'quantum computing' \u7684\u641c\u7d22\u7ed3\u679c 3  \n   **URL**: https://www.google.com/search?q=quantum+computing  \n   **Snippet**: \u8fd9\u662f\u5173\u4e8e 'quantum computing' \u7684\u8be6\u7ec6\u641c\u7d22\u7ed3\u679c\u6458\u8981 3\u3002\u5728\u5b9e\u9645\u4f7f\u7528\u4e2d\uff0c\u8fd9\u91cc\u4f1a\u663e\u793a\u901a\u8fc7SerpAPI\u83b7\u53d6\u7684\u771f\u5b9e\u641c\u7d22\u7ed3\u679c\u5185\u5bb9\u3002  \n   **Source**: Google\u641c\u7d22  \n   **Position**: 3  \n\n4. **Title**: \u5173\u4e8e 'quantum computing' \u7684\u641c\u7d22\u7ed3\u679c 4  \n   **URL**: https://www.google.com/search?q=quantum+computing  \n   **Snippet**: \u8fd9\u662f\u5173\u4e8e 'quantum computing' \u7684\u8be6\u7ec6\u641c\u7d22\u7ed3\u679c\u6458\u8981 4\u3002\u5728\u5b9e\u9645\u4f7f\u7528\u4e2d\uff0c\u8fd9\u91cc\u4f1a\u663e\u793a\u901a\u8fc7SerpAPI\u83b7\u53d6\u7684\u771f\u5b9e\u641c\u7d22\u7ed3\u679c\u5185\u5bb9\u3002  \n   **Source**: Google\u641c\u7d22  \n   **Position**: 4  \n\n5. **Title**: \u5173\u4e8e 'quantum computing' \u7684\u641c\u7d22\u7ed3\u679c 5  \n   **URL**: https://www.google.com/search?q=quantum+computing  \n   **Snippet**: \u8fd9\u662f\u5173\u4e8e 'quantum computing' \u7684\u8be6\u7ec6\u641c\u7d22\u7ed3\u679c\u6458\u8981 5\u3002\u5728\u5b9e\u9645\u4f7f\u7528\u4e2d\uff0c\u8fd9\u91cc\u4f1a\u663e\u793a\u901a\u8fc7SerpAPI\u83b7\u53d6\u7684\u771f\u5b9e\u641c\u7d22\u7ed3\u679c\u5185\u5bb9\u3002  \n   **Source**: Google\u641c\u7d22  \n   **Position**: 5  \n\n*Note: Results are in demo mode (SerpAPI key not configured). Real results would contain actual research papers or articles.*", "refusal": null, "role": "assistant", "annotations": null, "audio": null, "function_call": null, "tool_calls": null, "reasoning": "Okay, let me process this. The user asked for information on quantum computing. I used the serpapi_search tool with num_results set to 5. The response came back with five search results, but they all have placeholders like \"\u5173\u4e8e 'quantum computing' \u7684\u641c\u7d22\u7ed3\u679c 1\" and generic snippets. The note says it's in demo mode, so these aren't real results.\n\nThe user's instruction says if they asked for a list of papers, just return the list, not a summary. In this case, they didn't specify papers, but the search results are placeholder. I should check if the user wanted papers. Since the original query was just \"quantum computing\" without mentioning papers, but the assistant's response says to return the list of papers if asked. However, the user didn't ask for papers, just general info. But the tool response has demo results.\n\nWait, the user's instruction says: \"If the user asks for a list of papers, then give them the list of research papers you found and not the summary.\" The user didn't ask for papers, just \"quantum computing\". So the assistant should return the raw search results. The search results here are the fake ones from demo mode. So I need to present them as-is.\n\nBut the problem is the search results are all in Chinese placeholders. The titles say \"\u5173\u4e8e 'quantum computing' \u7684\u641c\u7d22\u7ed3\u679c 1\" which translates to \"Search results for 'quantum computing' 1\". The URLs are just Google search links. The snippets are also placeholders.\n\nThe user expects raw search results. So I should list them as they are. Even though they're demo, the task says to return the raw results. So I'll present the five results with title, URL, snippet, etc. as provided by the tool response.\n\nWait, the tool response has \"status\": \"success\" and the results. So I need to output those as the raw results. Let me check the exact format the user wants. The instructions say \"Return the raw search results.\"\n\nSo I'll list each result with title, URL, snippet. Even if they're fake, because that's what the tool returned. So the answer should be the list of the five results from the tool_response, formatted as per the example.\n"}}], "created": 1764054563, "model": "qwen3:30b", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_ollama", "usage": {"completion_tokens": 961, "prompt_tokens": 814, "total_tokens": 1775, "completion_tokens_details": null, "prompt_tokens_details": null}}


litellm_logging.py:2928 DEBUG:Filtered callbacks: []
cost_calculator.py:797 DEBUG:selected model name for cost calculation: openai/qwen3:30b
utils.py:4822 DEBUG:checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3:30b', 'combined_model_name': 'openai/qwen3:30b', 'stripped_model_name': 'qwen3:30b', 'combined_stripped_model_name': 'openai/qwen3:30b', 'custom_llm_provider': 'openai'}
utils.py:5064 DEBUG:Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
cost_calculator.py:1099 DEBUG:litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/qwen3:30b - This model isn't mapped yet. model=openai/qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
cost_calculator.py:797 DEBUG:selected model name for cost calculation: qwen3:30b
utils.py:4822 DEBUG:checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3:30b', 'combined_model_name': 'openai/qwen3:30b', 'stripped_model_name': 'qwen3:30b', 'combined_stripped_model_name': 'openai/qwen3:30b', 'custom_llm_provider': 'openai'}
utils.py:5064 DEBUG:Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
cost_calculator.py:1099 DEBUG:litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=qwen3:30b - This model isn't mapped yet. model=qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
litellm_logging.py:1328 DEBUG:response_cost_failure_debug_information: {'error_str': "This model isn't mapped yet. model=qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.", 'traceback_str': 'Traceback (most recent call last):\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/utils.py", line 4911, in _get_model_info_helper\n    raise ValueError(\n        "This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json"\n    )\nValueError: This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/litellm_core_utils/litellm_logging.py", line 1310, in _response_cost_calculator\n    response_cost = litellm.response_cost_calculator(\n        **response_cost_calculator_kwargs\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1220, in response_cost_calculator\n    raise e\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1203, in response_cost_calculator\n    response_cost = completion_cost(\n        completion_response=response_object,\n    ...<11 lines>...\n        service_tier=service_tier,\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1112, in completion_cost\n    raise e\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1105, in completion_cost\n    raise e\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1044, in completion_cost\n    ) = cost_per_token(\n        ~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<16 lines>...\n        response=completion_response,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 362, in cost_per_token\n    return openai_cost_per_token(\n        model=model, usage=usage_block, service_tier=service_tier\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/llms/openai/cost_calculation.py", line 33, in cost_per_token\n    return generic_cost_per_token(\n        model=model, usage=usage, custom_llm_provider="openai", service_tier=service_tier\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/litellm_core_utils/llm_cost_calc/utils.py", line 514, in generic_cost_per_token\n    model_info = get_model_info(model=model, custom_llm_provider=custom_llm_provider)\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/utils.py", line 5149, in get_model_info\n    _model_info = _get_model_info_helper(\n        model=model,\n        custom_llm_provider=custom_llm_provider,\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/utils.py", line 5067, in _get_model_info_helper\n    raise Exception(\n    ...<3 lines>...\n    )\nException: This model isn\'t mapped yet. model=qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n', 'model': 'qwen3:30b', 'cache_hit': False, 'custom_llm_provider': 'openai', 'base_model': None, 'call_type': 'acompletion', 'custom_pricing': False}
runners.py:1346 INFO:Closing runner...
runners.py:1354 INFO:Runner closed.
utils.py:375 DEBUG:Async Wrapper: Completed Call, calling async_success_handler: <bound method Logging.async_success_handler of <litellm.litellm_core_utils.litellm_logging.Logging object at 0x122c18550>>
litellm_logging.py:2928 DEBUG:Filtered callbacks: []
lite_llm.py:1162 DEBUG:
LLM Request:
-----------------------------------------------------------
System Instruction:
Your task is to find research papers and count them. 

    You MUST ALWAYS follow these steps:
    1) Find research papers on the user provided topic using the 'google_search_agent'. 
    2) Then, pass the papers to 'count_papers' tool to count the number of papers returned.
    3) Return both the list of research papers and the total number of papers.
    

You are an agent. Your internal name is "research_paper_finder_agent".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Find recent papers on quantum computing"}],"role":"user"}
{"parts":[{"function_call":{"id":"call_451ak1zq","args":{"request":"quantum computing"},"name":"google_search_agent"}}],"role":"model"}
{"parts":[{"function_response":{"id":"call_451ak1zq","name":"google_search_agent","response":{"result":"The raw search results for \"quantum computing\" are as follows:\n\n1. **Title**: ÂÖ≥‰∫é 'quantum computing' ÁöÑÊêúÁ¥¢ÁªìÊûú 1  \n   **URL**: https://www.google.com/search?q=quantum+computing  \n   **Snippet**: ËøôÊòØÂÖ≥‰∫é 'quantum computing' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 1„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \n   **Source**: GoogleÊêúÁ¥¢  \n   **Position**: 1  \n\n2. **Title**: ÂÖ≥‰∫é 'quantum computing' ÁöÑÊêúÁ¥¢ÁªìÊûú 2  \n   **URL**: https://www.google.com/search?q=quantum+computing  \n   **Snippet**: ËøôÊòØÂÖ≥‰∫é 'quantum computing' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 2„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \n   **Source**: GoogleÊêúÁ¥¢  \n   **Position**: 2  \n\n3. **Title**: ÂÖ≥‰∫é 'quantum computing' ÁöÑÊêúÁ¥¢ÁªìÊûú 3  \n   **URL**: https://www.google.com/search?q=quantum+computing  \n   **Snippet**: ËøôÊòØÂÖ≥‰∫é 'quantum computing' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 3„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \n   **Source**: GoogleÊêúÁ¥¢  \n   **Position**: 3  \n\n4. **Title**: ÂÖ≥‰∫é 'quantum computing' ÁöÑÊêúÁ¥¢ÁªìÊûú 4  \n   **URL**: https://www.google.com/search?q=quantum+computing  \n   **Snippet**: ËøôÊòØÂÖ≥‰∫é 'quantum computing' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 4„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \n   **Source**: GoogleÊêúÁ¥¢  \n   **Position**: 4  \n\n5. **Title**: ÂÖ≥‰∫é 'quantum computing' ÁöÑÊêúÁ¥¢ÁªìÊûú 5  \n   **URL**: https://www.google.com/search?q=quantum+computing  \n   **Snippet**: ËøôÊòØÂÖ≥‰∫é 'quantum computing' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 5„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \n   **Source**: GoogleÊêúÁ¥¢  \n   **Position**: 5  \n\n*Note: Results are in demo mode (SerpAPI key not configured). Real results would contain actual research papers or articles.*"}}},{"text":"Handle the requests as specified in the System Instruction."}],"role":"user"}
-----------------------------------------------------------
Functions:
google_search_agent: {'request': {'type': <Type.STRING: 'STRING'>}} -> None
count_papers: {'papers': {'type': <Type.STRING: 'STRING'>}} -> None
-----------------------------------------------------------

utils.py:375 DEBUG:

utils.py:375 DEBUG:[92mRequest to litellm:[0m
utils.py:375 DEBUG:[92mlitellm.acompletion(model='qwen3:30b', messages=[{'role': 'developer', 'content': 'Your task is to find research papers and count them. \n\n    You MUST ALWAYS follow these steps:\n    1) Find research papers on the user provided topic using the \'google_search_agent\'. \n    2) Then, pass the papers to \'count_papers\' tool to count the number of papers returned.\n    3) Return both the list of research papers and the total number of papers.\n    \n\nYou are an agent. Your internal name is "research_paper_finder_agent".'}, {'role': 'user', 'content': 'Find recent papers on quantum computing'}, {'role': 'assistant', 'content': None, 'tool_calls': [{'type': 'function', 'id': 'call_451ak1zq', 'function': {'name': 'google_search_agent', 'arguments': '{"request": "quantum computing"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_451ak1zq', 'content': '{"result": "The raw search results for \\"quantum computing\\" are as follows:\\n\\n1. **Title**: ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 1  \\n   **URL**: https://www.google.com/search?q=quantum+computing  \\n   **Snippet**: ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 1„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \\n   **Source**: GoogleÊêúÁ¥¢  \\n   **Position**: 1  \\n\\n2. **Title**: ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 2  \\n   **URL**: https://www.google.com/search?q=quantum+computing  \\n   **Snippet**: ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 2„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \\n   **Source**: GoogleÊêúÁ¥¢  \\n   **Position**: 2  \\n\\n3. **Title**: ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 3  \\n   **URL**: https://www.google.com/search?q=quantum+computing  \\n   **Snippet**: ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 3„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \\n   **Source**: GoogleÊêúÁ¥¢  \\n   **Position**: 3  \\n\\n4. **Title**: ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 4  \\n   **URL**: https://www.google.com/search?q=quantum+computing  \\n   **Snippet**: ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 4„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \\n   **Source**: GoogleÊêúÁ¥¢  \\n   **Position**: 4  \\n\\n5. **Title**: ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 5  \\n   **URL**: https://www.google.com/search?q=quantum+computing  \\n   **Snippet**: ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 5„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \\n   **Source**: GoogleÊêúÁ¥¢  \\n   **Position**: 5  \\n\\n*Note: Results are in demo mode (SerpAPI key not configured). Real results would contain actual research papers or articles.*"}'}], tools=[{'type': 'function', 'function': {'name': 'google_search_agent', 'description': 'Searches for information using Google search', 'parameters': {'type': 'object', 'properties': {'request': {'type': 'string'}}, 'required': ['request']}}}, {'type': 'function', 'function': {'name': 'count_papers', 'description': '\nThis function counts the number of papers in a list of strings.\nArgs:\n  papers: A list of strings, where each string is a research paper.\nReturns:\n  The number of papers in the list.\n', 'parameters': {'type': 'object', 'properties': {'papers': {'type': 'string'}}, 'required': ['papers']}}}], response_format=None, api_base='http://localhost:11434/v1', custom_llm_provider='openai', api_key='ollama')[0m
utils.py:375 DEBUG:

litellm_logging.py:488 DEBUG:self.optional_params: {}
utils.py:375 DEBUG:ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None
main.py:501 DEBUG:üîÑ NO SHARED SESSION: acompletion called without shared_session
base_utils.py:219 DEBUG:Translating developer role to system role for non-OpenAI providers.
utils.py:375 DEBUG:Logging Details LiteLLM-Async Success Call, cache_hit=None
utils.py:3421 INFO:
LiteLLM completion() model= qwen3:30b; provider = openai
utils.py:4822 DEBUG:checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3:30b', 'combined_model_name': 'openai/qwen3:30b', 'stripped_model_name': 'qwen3:30b', 'combined_stripped_model_name': 'openai/qwen3:30b', 'custom_llm_provider': 'openai'}
utils.py:3424 DEBUG:
LiteLLM: Params passed to completion() {'model': 'qwen3:30b', 'functions': None, 'function_call': None, 'temperature': None, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': [{'type': 'function', 'function': {'name': 'google_search_agent', 'description': 'Searches for information using Google search', 'parameters': {'type': 'object', 'properties': {'request': {'type': 'string'}}, 'required': ['request']}}}, {'type': 'function', 'function': {'name': 'count_papers', 'description': '\nThis function counts the number of papers in a list of strings.\nArgs:\n  papers: A list of strings, where each string is a research paper.\nReturns:\n  The number of papers in the list.\n', 'parameters': {'type': 'object', 'properties': {'papers': {'type': 'string'}}, 'required': ['papers']}}}], 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': 'Your task is to find research papers and count them. \n\n    You MUST ALWAYS follow these steps:\n    1) Find research papers on the user provided topic using the \'google_search_agent\'. \n    2) Then, pass the papers to \'count_papers\' tool to count the number of papers returned.\n    3) Return both the list of research papers and the total number of papers.\n    \n\nYou are an agent. Your internal name is "research_paper_finder_agent".'}, {'role': 'user', 'content': 'Find recent papers on quantum computing'}, {'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_451ak1zq', 'function': {'name': 'google_search_agent', 'arguments': '{"request": "quantum computing"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_451ak1zq', 'content': '{"result": "The raw search results for \\"quantum computing\\" are as follows:\\n\\n1. **Title**: ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 1  \\n   **URL**: https://www.google.com/search?q=quantum+computing  \\n   **Snippet**: ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 1„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \\n   **Source**: GoogleÊêúÁ¥¢  \\n   **Position**: 1  \\n\\n2. **Title**: ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 2  \\n   **URL**: https://www.google.com/search?q=quantum+computing  \\n   **Snippet**: ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 2„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \\n   **Source**: GoogleÊêúÁ¥¢  \\n   **Position**: 2  \\n\\n3. **Title**: ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 3  \\n   **URL**: https://www.google.com/search?q=quantum+computing  \\n   **Snippet**: ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 3„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \\n   **Source**: GoogleÊêúÁ¥¢  \\n   **Position**: 3  \\n\\n4. **Title**: ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 4  \\n   **URL**: https://www.google.com/search?q=quantum+computing  \\n   **Snippet**: ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 4„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \\n   **Source**: GoogleÊêúÁ¥¢  \\n   **Position**: 4  \\n\\n5. **Title**: ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 5  \\n   **URL**: https://www.google.com/search?q=quantum+computing  \\n   **Snippet**: ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 5„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \\n   **Source**: GoogleÊêúÁ¥¢  \\n   **Position**: 5  \\n\\n*Note: Results are in demo mode (SerpAPI key not configured). Real results would contain actual research papers or articles.*"}'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
utils.py:5064 DEBUG:Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
utils.py:3427 DEBUG:
LiteLLM: Non-Default params passed to completion() {'tools': [{'type': 'function', 'function': {'name': 'google_search_agent', 'description': 'Searches for information using Google search', 'parameters': {'type': 'object', 'properties': {'request': {'type': 'string'}}, 'required': ['request']}}}, {'type': 'function', 'function': {'name': 'count_papers', 'description': '\nThis function counts the number of papers in a list of strings.\nArgs:\n  papers: A list of strings, where each string is a research paper.\nReturns:\n  The number of papers in the list.\n', 'parameters': {'type': 'object', 'properties': {'papers': {'type': 'string'}}, 'required': ['papers']}}}]}
litellm_logging.py:4180 DEBUG:Model=qwen3:30b is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload
utils.py:375 DEBUG:Final returned optional params: {'tools': [{'type': 'function', 'function': {'name': 'google_search_agent', 'description': 'Searches for information using Google search', 'parameters': {'type': 'object', 'properties': {'request': {'type': 'string'}}, 'required': ['request']}}}, {'type': 'function', 'function': {'name': 'count_papers', 'description': '\nThis function counts the number of papers in a list of strings.\nArgs:\n  papers: A list of strings, where each string is a research paper.\nReturns:\n  The number of papers in the list.\n', 'parameters': {'type': 'object', 'properties': {'papers': {'type': 'string'}}, 'required': ['papers']}}}], 'extra_body': {}}
utils.py:375 DEBUG:Async success callbacks: Got a complete streaming response
litellm_logging.py:488 DEBUG:self.optional_params: {'tools': [{'type': 'function', 'function': {'name': 'google_search_agent', 'description': 'Searches for information using Google search', 'parameters': {'type': 'object', 'properties': {'request': {'type': 'string'}}, 'required': ['request']}}}, {'type': 'function', 'function': {'name': 'count_papers', 'description': '\nThis function counts the number of papers in a list of strings.\nArgs:\n  papers: A list of strings, where each string is a research paper.\nReturns:\n  The number of papers in the list.\n', 'parameters': {'type': 'object', 'properties': {'papers': {'type': 'string'}}, 'required': ['papers']}}}], 'extra_body': {}}
cost_calculator.py:797 DEBUG:selected model name for cost calculation: openai/qwen3:30b
utils.py:4822 DEBUG:checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3:30b', 'combined_model_name': 'openai/qwen3:30b', 'stripped_model_name': 'qwen3:30b', 'combined_stripped_model_name': 'openai/qwen3:30b', 'custom_llm_provider': 'openai'}
utils.py:4822 DEBUG:checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3:30b', 'combined_model_name': 'openai/qwen3:30b', 'stripped_model_name': 'qwen3:30b', 'combined_stripped_model_name': 'openai/qwen3:30b', 'custom_llm_provider': 'openai'}
utils.py:5064 DEBUG:Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
utils.py:5064 DEBUG:Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
main.py:924 DEBUG:Error getting model info: This model isn't mapped yet. model=qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
cost_calculator.py:1099 DEBUG:litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/qwen3:30b - This model isn't mapped yet. model=openai/qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
cost_calculator.py:797 DEBUG:selected model name for cost calculation: qwen3:30b
utils.py:4822 DEBUG:checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3:30b', 'combined_model_name': 'openai/qwen3:30b', 'stripped_model_name': 'qwen3:30b', 'combined_stripped_model_name': 'openai/qwen3:30b', 'custom_llm_provider': 'openai'}
utils.py:5064 DEBUG:Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
cost_calculator.py:1099 DEBUG:litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=qwen3:30b - This model isn't mapped yet. model=qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
litellm_logging.py:1328 DEBUG:response_cost_failure_debug_information: {'error_str': "This model isn't mapped yet. model=qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.", 'traceback_str': 'Traceback (most recent call last):\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/utils.py", line 4911, in _get_model_info_helper\n    raise ValueError(\n        "This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json"\n    )\nValueError: This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/litellm_core_utils/litellm_logging.py", line 1310, in _response_cost_calculator\n    response_cost = litellm.response_cost_calculator(\n        **response_cost_calculator_kwargs\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1220, in response_cost_calculator\n    raise e\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1203, in response_cost_calculator\n    response_cost = completion_cost(\n        completion_response=response_object,\n    ...<11 lines>...\n        service_tier=service_tier,\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1112, in completion_cost\n    raise e\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1105, in completion_cost\n    raise e\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 1044, in completion_cost\n    ) = cost_per_token(\n        ~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<16 lines>...\n        response=completion_response,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/cost_calculator.py", line 362, in cost_per_token\n    return openai_cost_per_token(\n        model=model, usage=usage_block, service_tier=service_tier\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/llms/openai/cost_calculation.py", line 33, in cost_per_token\n    return generic_cost_per_token(\n        model=model, usage=usage, custom_llm_provider="openai", service_tier=service_tier\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/litellm_core_utils/llm_cost_calc/utils.py", line 514, in generic_cost_per_token\n    model_info = get_model_info(model=model, custom_llm_provider=custom_llm_provider)\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/utils.py", line 5149, in get_model_info\n    _model_info = _get_model_info_helper(\n        model=model,\n        custom_llm_provider=custom_llm_provider,\n    )\n  File "/Users/looboo/miniconda3/envs/py313/lib/python3.13/site-packages/litellm/utils.py", line 5067, in _get_model_info_helper\n    raise Exception(\n    ...<3 lines>...\n    )\nException: This model isn\'t mapped yet. model=qwen3:30b, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n', 'model': 'qwen3:30b', 'cache_hit': None, 'custom_llm_provider': 'openai', 'base_model': None, 'call_type': 'acompletion', 'custom_pricing': False}
litellm_logging.py:2265 DEBUG:Model=qwen3:30b; cost=None
utils.py:4822 DEBUG:checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3:30b', 'combined_model_name': 'openai/qwen3:30b', 'stripped_model_name': 'qwen3:30b', 'combined_stripped_model_name': 'openai/qwen3:30b', 'custom_llm_provider': 'openai'}
utils.py:5064 DEBUG:Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
litellm_logging.py:4180 DEBUG:Model=qwen3:30b is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload
litellm_logging.py:961 DEBUG:[92m

POST Request Sent from LiteLLM:
curl -X POST \
http://localhost:11434/v1/ \
-H 'Authorization: Be****ma' \
-d '{'model': 'qwen3:30b', 'messages': [{'role': 'system', 'content': 'Your task is to find research papers and count them. \n\n    You MUST ALWAYS follow these steps:\n    1) Find research papers on the user provided topic using the \'google_search_agent\'. \n    2) Then, pass the papers to \'count_papers\' tool to count the number of papers returned.\n    3) Return both the list of research papers and the total number of papers.\n    \n\nYou are an agent. Your internal name is "research_paper_finder_agent".'}, {'role': 'user', 'content': 'Find recent papers on quantum computing'}, {'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_451ak1zq', 'function': {'name': 'google_search_agent', 'arguments': '{"request": "quantum computing"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_451ak1zq', 'content': '{"result": "The raw search results for \\"quantum computing\\" are as follows:\\n\\n1. **Title**: ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 1  \\n   **URL**: https://www.google.com/search?q=quantum+computing  \\n   **Snippet**: ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 1„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \\n   **Source**: GoogleÊêúÁ¥¢  \\n   **Position**: 1  \\n\\n2. **Title**: ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 2  \\n   **URL**: https://www.google.com/search?q=quantum+computing  \\n   **Snippet**: ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 2„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \\n   **Source**: GoogleÊêúÁ¥¢  \\n   **Position**: 2  \\n\\n3. **Title**: ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 3  \\n   **URL**: https://www.google.com/search?q=quantum+computing  \\n   **Snippet**: ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 3„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \\n   **Source**: GoogleÊêúÁ¥¢  \\n   **Position**: 3  \\n\\n4. **Title**: ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 4  \\n   **URL**: https://www.google.com/search?q=quantum+computing  \\n   **Snippet**: ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 4„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \\n   **Source**: GoogleÊêúÁ¥¢  \\n   **Position**: 4  \\n\\n5. **Title**: ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 5  \\n   **URL**: https://www.google.com/search?q=quantum+computing  \\n   **Snippet**: ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 5„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \\n   **Source**: GoogleÊêúÁ¥¢  \\n   **Position**: 5  \\n\\n*Note: Results are in demo mode (SerpAPI key not configured). Real results would contain actual research papers or articles.*"}'}], 'tools': [{'type': 'function', 'function': {'name': 'google_search_agent', 'description': 'Searches for information using Google search', 'parameters': {'type': 'object', 'properties': {'request': {'type': 'string'}}, 'required': ['request']}}}, {'type': 'function', 'function': {'name': 'count_papers', 'description': '\nThis function counts the number of papers in a list of strings.\nArgs:\n  papers: A list of strings, where each string is a research paper.\nReturns:\n  The number of papers in the list.\n', 'parameters': {'type': 'object', 'properties': {'papers': {'type': 'string'}}, 'required': ['papers']}}}], 'extra_body': {}}'
[0m

_base_client.py:482 DEBUG:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-cc6ae9be-ae25-4986-805b-69479417cba7', 'json_data': {'messages': [{'role': 'system', 'content': 'Your task is to find research papers and count them. \n\n    You MUST ALWAYS follow these steps:\n    1) Find research papers on the user provided topic using the \'google_search_agent\'. \n    2) Then, pass the papers to \'count_papers\' tool to count the number of papers returned.\n    3) Return both the list of research papers and the total number of papers.\n    \n\nYou are an agent. Your internal name is "research_paper_finder_agent".'}, {'role': 'user', 'content': 'Find recent papers on quantum computing'}, {'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_451ak1zq', 'function': {'name': 'google_search_agent', 'arguments': '{"request": "quantum computing"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_451ak1zq', 'content': '{"result": "The raw search results for \\"quantum computing\\" are as follows:\\n\\n1. **Title**: ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 1  \\n   **URL**: https://www.google.com/search?q=quantum+computing  \\n   **Snippet**: ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 1„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \\n   **Source**: GoogleÊêúÁ¥¢  \\n   **Position**: 1  \\n\\n2. **Title**: ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 2  \\n   **URL**: https://www.google.com/search?q=quantum+computing  \\n   **Snippet**: ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 2„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \\n   **Source**: GoogleÊêúÁ¥¢  \\n   **Position**: 2  \\n\\n3. **Title**: ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 3  \\n   **URL**: https://www.google.com/search?q=quantum+computing  \\n   **Snippet**: ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 3„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \\n   **Source**: GoogleÊêúÁ¥¢  \\n   **Position**: 3  \\n\\n4. **Title**: ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 4  \\n   **URL**: https://www.google.com/search?q=quantum+computing  \\n   **Snippet**: ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 4„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \\n   **Source**: GoogleÊêúÁ¥¢  \\n   **Position**: 4  \\n\\n5. **Title**: ÂÖ≥‰∫é \'quantum computing\' ÁöÑÊêúÁ¥¢ÁªìÊûú 5  \\n   **URL**: https://www.google.com/search?q=quantum+computing  \\n   **Snippet**: ËøôÊòØÂÖ≥‰∫é \'quantum computing\' ÁöÑËØ¶ÁªÜÊêúÁ¥¢ÁªìÊûúÊëòË¶Å 5„ÄÇÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåËøôÈáå‰ºöÊòæÁ§∫ÈÄöËøáSerpAPIËé∑ÂèñÁöÑÁúüÂÆûÊêúÁ¥¢ÁªìÊûúÂÜÖÂÆπ„ÄÇ  \\n   **Source**: GoogleÊêúÁ¥¢  \\n   **Position**: 5  \\n\\n*Note: Results are in demo mode (SerpAPI key not configured). Real results would contain actual research papers or articles.*"}'}], 'model': 'qwen3:30b', 'tools': [{'type': 'function', 'function': {'name': 'google_search_agent', 'description': 'Searches for information using Google search', 'parameters': {'type': 'object', 'properties': {'request': {'type': 'string'}}, 'required': ['request']}}}, {'type': 'function', 'function': {'name': 'count_papers', 'description': '\nThis function counts the number of papers in a list of strings.\nArgs:\n  papers: A list of strings, where each string is a research paper.\nReturns:\n  The number of papers in the list.\n', 'parameters': {'type': 'object', 'properties': {'papers': {'type': 'string'}}, 'required': ['papers']}}}]}, 'extra_json': {}}
_base_client.py:1525 DEBUG:Sending HTTP Request: POST http://localhost:11434/v1/chat/completions
