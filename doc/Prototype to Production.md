# 从原型到量产：AI 智能体落地实战指南
作者：索克拉蒂斯·卡尔塔基斯（Sokratis Kartakis）、加布里埃拉·埃尔南德斯·拉里约斯（Gabriela Hernandez Larios）、李然（Ran Li）、埃利亚·塞基（Elia Secchi）、黄霞（Huang Xia）  
谷歌公司（Google）出品  

## 致谢
### 内容贡献者
德里克·伊根（Derek Egan）、蔡斯·莱尔（Chase Lyall）、阿南特·纳瓦尔加里亚（Anant Nawalgaria）、拉维·尼甘（Lavi Nigam）、坎查娜·帕特洛拉（Kanchana Patlolla）、迈克尔·瓦科克（Michael Vakoc）

### 策划与编辑
阿南特·纳瓦尔加里亚（Anant Nawalgaria）、坎查娜·帕特洛拉（Kanchana Patlolla）

### 设计师
迈克尔·兰宁（Michael Lanning）

2025年11月  


# 目录
1. 摘要 5
2. 引言：从原型到量产 6
3. 人员与流程 8
4. 量产落地全流程 11
5. 评估：质量的“守门人” 12
6. 自动化 CI/CD 流水线 13
7. 安全发布策略 15
8. 从源头筑牢安全防线 17
9. 量产阶段的运维工作 19
    - 监测：智能体的“感官系统” 19
    - 行动：运维调控的“操作杆” 20
    - 系统健康管理：性能、成本与规模 20
    - 风险管控：安全响应操作手册 22
    - 迭代：从量产中学习优化 22
10. 迭代引擎：自动化量产路径 23
11. 迭代流程：从洞察到落地优化 24
12. 安全迭代：量产反馈闭环 25
13. 突破单智能体运维局限 26
    - A2A 协议：可复用与标准化 27
    - A2A 协议：从概念到落地 28
    - A2A 与 MCP 如何协同工作 33
14. 注册中心架构：何时建、怎么建 35
15. 整合落地：AgentOps 生命周期 36
16. 结语：用 AgentOps 打通量产“最后一公里” 38
17. 附注 40


# 从原型到量产
做个智能体不难，信得过它才难。

## 摘要
这份白皮书是 AI 智能体运维生命周期的全方位技术指南，重点讲智能体的部署、扩容和量产落地。之前在“第4天”的内容里，我们已经聊过智能体的评估和监测，这份指南在此基础上，进一步说明如何通过稳健的 CI/CD 流水线和可扩容的基础设施，建立足够的信任，让智能体顺利进入量产阶段。

文中还探讨了把“智能体系统”从原型升级为企业级解决方案时会遇到的难题，尤其关注 Agent2Agent（A2A，智能体间通信）的互操作性。无论你是 AI/ML 工程师、DevOps 从业者，还是系统架构师，都能从这份指南里找到实用的干货。

2025年11月  


# 引言：从原型到量产
花几分钟，甚至几秒钟，就能搭出一个 AI 智能体原型。但要把这个“看起来很厉害”的demo，变成企业能放心用、靠得住的量产级系统，才是真正的硬骨头。这就是我们常说的量产“最后一公里”鸿沟——根据我们和客户的实际合作经验，大概80%的精力都不是花在智能体的核心智能上，而是用在搭建基础设施、筑牢安全防线、做验证测试上，只有这样才能让智能体靠谱、安全。

要是跳过这些收尾步骤，麻烦可就大了。比如：
- 客服智能体被人骗了，免费送出去一堆产品——就因为没设好“防护栏”；
- 用户居然能通过你的智能体访问公司内部的机密数据库——就因为身份验证配置错了；
- 周末的时候，智能体突然产生了一大笔消耗账单，没人知道为啥——就因为没装监测系统；
- 昨天还好好的关键智能体，今天突然崩了，团队手忙脚乱——就因为没做持续评估。

这些可不是单纯的技术问题，而是会给业务带来巨大损失的故障。虽说 DevOps 和 MLOps 的原则能打个好基础，但光靠这些还不够。部署智能体系统会遇到一类全新的难题，需要我们在运维规范上升级迭代。

和传统的机器学习模型不一样，智能体是能自主交互、有“状态记忆”的，执行路径还会动态变化。这就带来了很多独特的运维麻烦，得用专门的策略来解决：
- 动态工具调度：智能体会自己选工具、搭“执行路径”，每次的行为都可能不一样。这就需要完善的版本管理、权限控制和监测机制；
- 可扩容的状态管理：智能体能记住多次交互的信息，但要安全、稳定地管理大规模的会话和记忆数据，是个很复杂的系统设计问题；
- 不可预测的成本与延迟：智能体找答案的路径千差万别，要是没做好智能预算和缓存，成本和响应时间根本没法把控。

要搞定这些难题，得靠三大核心支柱：自动化评估、自动化部署（CI/CD）和全方位监测。

这份白皮书就是你的“ step-by-step 操作手册”，帮你搭好这个基础，走完量产之路！我们先从量产前的核心准备说起，教你怎么搭自动化 CI/CD 流水线，怎么用严格的评估当好“质量守门人”；接着深入聊聊智能体“上线后”的难题，比如扩容策略、性能调优和实时监测；最后再带你看看多智能体系统的新方向——A2A 协议，讲讲怎么让智能体之间安全、高效地“沟通协作”。

2025年11月  


# 实战落地指南
在这份白皮书里，所有实战案例都会参考“谷歌云平台智能体 starter 包”（Google Cloud Platform Agent Starter Pack1-1a）这个 Python 工具包。它能提供可直接用于量产的生成式 AI 智能体模板，里面有现成的智能体、自动化 CI/CD 配置、Terraform 部署工具、Vertex AI 评估集成功能，还有谷歌云自带的监测能力。这个 starter 包用可运行的代码把文中的概念落地，你几分钟就能部署好。


# 人员与流程
前面聊了那么多 CI/CD、监测和动态流水线，为啥现在要重点说“人员与流程”呢？因为再牛的技术，要是没有合适的团队来搭建、管理和管控，也发挥不了作用。

你以为客服智能体是自己“天生”就不会乱送产品的吗？其实是 AI 工程师和提示词工程师设计、搭建了“防护栏”；机密数据库的安全也不是靠“抽象概念”保障的，是云平台团队配置好了身份验证。每一个能顺利量产的智能体背后，都有一群分工明确、配合默契的专业人员——接下来我们就聊聊这些核心角色。

2025年11月  


## MLOps 相关人员
机器学习与运维（MLOps），是靠“人、流程、技术”三者结合，高效地把机器学习解决方案推向量产的体系。

（图1：一张示意图，展示“运维（Ops）”是“人、流程、技术”的交集）

在传统的 MLOps 体系里，主要有这么几个核心团队：
- 云平台团队：成员包括云架构师、管理员和安全专家，负责搭建基础云基础设施、保障安全和管控权限。他们会给工程师和服务账号分配“最小权限”——只给必要的资源访问权，不多给；
- 数据工程团队：数据工程师和数据负责人负责搭建、维护数据流水线，处理数据的采集、预处理，还得保证数据质量；
- 数据科学与 MLOps 团队：里面有数据科学家（负责模型的实验和训练），还有 ML 工程师（用 CI/CD 把机器学习的全流程——比如预处理、训练、后处理——自动化、规模化）。MLOps 工程师则负责搭建、维护标准化的流水线基础设施，给团队打辅助；
- 机器学习管控团队：这是个中心化的团队，成员包括产品负责人和审计员，负责监管机器学习的全生命周期。他们还会保管所有的“工件”（比如模型文件、数据）和指标数据，确保合规、透明、可追溯。

生成式 AI 给这个体系增加了一层复杂度，也催生了一些新的专业角色：
- 提示词工程师：这个职位名称在行业里还在演变，但做这个工作的人，既要会写高效的提示词，又得懂具体业务领域的知识。他们要确定“该问模型什么问题”“期望模型给出什么答案”。不过在实际工作中，这个活儿可能是 AI 工程师、业务专家或者专门的人员来做，具体看公司的成熟度；
- AI 工程师：负责把生成式 AI 解决方案规模化推向量产，搭建稳健的后端系统——里面要包含大规模评估、防护栏、RAG（检索增强生成）和工具集成功能；
- DevOps/应用开发工程师：这些工程师负责搭建前端组件和用户友好的界面，让前端能和生成式 AI 后端对接。

公司的规模和架构会影响这些角色的分工：小公司里，一个人可能要干好几个人的活；成熟的大公司里，团队分工就更细、更专业。要把这些不同角色的人协调好，才能搭起稳健的运维基础，顺利把传统机器学习和生成式 AI 项目推向量产。

2025年11月  


（图2：多团队如何协作，让模型和生成式 AI 应用落地运维）

# 量产落地全流程
前面已经明确了团队构成，现在来说说“流程”——怎么把这些专业人员的工作整合起来，做出一个靠谱、可信、能给用户用的系统？

答案就藏在一套严谨的“量产前流程”里，核心原则只有一个：“评估守门，合格再部署”。道理很简单，但作用很大：任何一个版本的智能体，必须先通过全面评估，证明质量和安全性都达标，才能交给用户用。

在量产前这个阶段，我们要把“手动操作的不确定性”换成“自动化带来的信心”，具体要靠三大支柱：
1. 严格的评估流程：当好“质量守门人”；
2. 自动化 CI/CD 流水线：把评估流程落地执行；
3. 安全发布策略：降低最后一步量产部署的风险。

2025年11月  


# 评估：质量的“守门人”
为啥智能体需要专门的“质量守门人”呢？因为传统软件测试对付不了“会推理、能适应”的系统。而且评估智能体和评估大语言模型（LLM）不一样——不能只看最终答案对不对，还得看智能体完成任务的“整个推理过程和操作步骤”。哪怕智能体的工具通过了100次单元测试，要是它选错了工具，或者瞎编答案，照样会出大问题。所以我们要评估的是它的“行为质量”，不只是“功能正确性”。

这个“质量守门人”主要有两种实现方式：

## 1. 手动“提交代码前”评估（Pre-PR 评估）
适合两种情况：团队想要灵活度，或者刚开始做评估。具体流程是：在提交代码（PR）之前，负责智能体行为的人（比如 AI 工程师、提示词工程师，看你们公司怎么分工）要在本地跑一遍评估套件，然后把“新智能体和量产版本的性能对比报告”附在 PR 描述里——也就是说，评估结果是必须提交的“材料”。

接下来，审核人（通常是另一位 AI 工程师，或者机器学习管控团队的人）不仅要审核代码，还得检查智能体的行为变化：有没有违反“防护栏”规则？会不会被注入恶意提示词？

## 2. 流水线内自动化评估
适合成熟的团队。数据科学与 MLOps 团队搭建、维护的“评估工具包”会直接集成到 CI/CD 流水线里。只要评估不通过，部署就会自动被卡住——这是用代码严格执行机器学习管控团队定的质量标准。这种方式虽然少了手动审核的灵活度，但胜在自动化带来的一致性。

具体怎么操作？可以把 CI/CD 流水线配置成：自动触发评估任务，让新智能体的响应和“黄金数据集”（提前选好的、有代表性的测试用例集合，专门用来检查智能体的预期行为和是否遵守防护栏规则）做对比。要是关键指标——比如“工具调用成功率”“有用性评分”——低于预设的阈值，部署就会被自动拦下。

不管用哪种方式，核心原则都一样：智能体必须过了质量关，才能进量产。

至于“该测什么”“怎么搭评估工具包”，我们在“第4天”的深度内容《智能体质量：监测、日志、追踪、评估、指标》里已经详细讲过了——从怎么编“黄金数据集”，到怎么用“大语言模型当裁判”（LLM-as-a-judge），再到怎么用 Vertex AI 评估工具2来做评估，都有覆盖。

2025年11月  


# 自动化 CI/CD 流水线
AI 智能体是个“组合系统”，不只是源代码，还包括提示词、工具定义和配置文件。这种复杂性会带来不少难题：改个提示词，会不会让工具性能下降？把这些“组件”都整合好之前，怎么测试它们之间的配合？

答案就是 CI/CD（持续集成/持续部署）流水线。它不只是个自动化脚本，更是一套结构化流程——能帮团队里不同角色的人协作，搞定复杂性，保证质量。具体做法是“分阶段测试”：每一步都慢慢积累信心，最后再把智能体交给用户。

一个稳健的流水线就像个“漏斗”，要尽早、尽可能低成本地找出问题——这就是常说的“左移（shift left）”原则。流水线会把“快速的代码合并前检查”和“更全面、耗资源的代码合并后部署”分开，通常分三个阶段：

## 1. 阶段一：合并前集成（CI）
流水线的第一个任务，是给提交代码（PR）的 AI 工程师或提示词工程师“快速反馈”。只要有人开了 PR，这个 CI 阶段就会自动触发，相当于“主分支的守门人”。

这个阶段会跑一些快节奏的检查：单元测试、代码风格检查（linting）、依赖包扫描。更关键的是，提示词工程师设计的“智能体质量评估套件”也适合在这个阶段跑——能马上知道“改了之后，智能体在关键场景下的性能是变好了还是变差了”，避免有问题的代码混入主分支。

比如“智能体 starter 包”（Agent Starter Pack1，简称 ASP）生成的“PR 检查配置模板”3，就是用 Cloud Build4 工具实现这个阶段的好例子。

## 2. 阶段二：合并后验证（部署到预发布环境，CD）
要是代码通过了所有 CI 检查（包括性能评估），并且合并到了主分支，接下来的重点就从“代码和性能正确性”变成“整个集成系统的运维就绪度”。

这个持续部署（CD）流程通常由 MLOps 团队负责：先把智能体打包，然后部署到“预发布环境（staging）”——这个环境和量产环境几乎一模一样。在预发布环境里，要跑一些更全面、更耗资源的测试，比如压力测试、和远程服务的集成测试。

还有个关键步骤叫“内部测试（dogfooding）”——让公司内部员工先用用这个智能体，给点定性反馈，再交给最终用户。这样能确保“作为集成系统的智能体”在接近量产的环境下，能稳定、高效地运行。ASP 里的“预发布部署模板”5，就是这个阶段的部署示例。

## 3. 阶段三： gated 部署（部署到量产环境）
智能体在预发布环境里经过全面验证后，最后一步就是部署到量产环境。但这一步几乎不会完全自动化，通常需要产品负责人最终确认——也就是“人在回路（human-in-the-loop）”。

一旦批准，就会把“在预发布环境里测试验证过的那个部署包”直接推到量产环境。ASP 生成的“量产部署模板”6，就展示了怎么拿到这个验证过的部署包，再加上适当的防护措施，把它部署到量产环境。

2025年11月  


（图3：CI/CD 流程的不同阶段：代码提交（PR）→ 合并到主分支，触发 CI 流水线（单元测试、集成测试）和 CD 流水线1（容器构建、部署到预发布环境）、CD 流水线2（压力测试、部署到量产环境））

要实现这个三阶段 CI/CD 流程，得有稳健的自动化基础设施和妥善的密钥管理。驱动这套自动化的核心技术有两个：

### 1. 基础设施即代码（IaC）
像 Terraform 这样的工具，能把环境配置用代码写出来，确保环境一致、可重复创建，还能做版本管理。比如 ASP 生成的“Terraform 模板”7，就包含了完整的智能体基础设施配置——包括 Vertex AI、Cloud Run、BigQuery 这些资源。

### 2. 自动化测试框架
像 Pytest 这样的框架，能在每个阶段执行测试和评估，还能处理智能体特有的“工件”——比如对话历史、工具调用日志、动态推理轨迹。

另外，工具的 API 密钥这类敏感信息，绝对不能硬编码在代码仓库里，要用工具有安全管理服务（比如 Secret Manager8），在智能体运行时再把密钥注入到环境里。


# 安全发布策略
虽然量产前的全面检查很重要，但实际应用中难免会遇到没预料到的问题。与其一下子让所有用户都用新版本，不如用“逐步发布”的方式，配合细致的监测，把风险降到最低。

这里有四个经过验证的好方法，能帮团队在部署时更有信心：

## 1. 金丝雀发布（Canary）
先让1%的用户用新版本，重点监测有没有“恶意提示词注入”和“异常工具使用”。要是没问题，再慢慢扩大范围；一旦发现问题，能马上回滚。

## 2. 蓝绿部署（Blue-Green）
同时跑两个一模一样的量产环境：“蓝环境”正常给用户提供服务，“绿环境”用来部署新版本。部署好之后，一下子把流量切到绿环境；要是出问题，马上切回蓝环境——零停机，恢复快。

## 3. A/B 测试
让不同版本的智能体在真实用户身上跑，对比业务指标（比如用户满意度、任务完成率），用数据决定哪个版本更好。内部员工或外部用户都能参与测试。

## 4. 功能开关（Feature Flags）
先把代码部署到量产环境，但用开关控制功能是否开放——先让特定用户测试新功能，没问题再全量放开。

这四种方法有个共同的基础：**严格的版本管理**。不管是代码、提示词、模型接口，还是工具 schema、记忆结构，甚至评估数据集——所有组件都要做版本管理。万一出了问题，就能马上回滚到“已知可用”的版本，相当于给量产加了个“撤销键”！

你可以用 Agent Engine9 或 Cloud Run10 部署智能体，然后用 Cloud Load Balancing11 管理不同版本的流量，或者和其他微服务对接。而且“智能体 starter 包”1 里有现成的 GitOps 工作流模板——每一次部署对应一次 Git 提交，每一次回滚对应一次 Git 撤销，代码仓库既是“当前状态的唯一来源”，也记录了完整的部署历史。

2025年11月  


# 从源头筑牢安全防线
安全发布策略能帮你规避 bug 和故障，但智能体还有个独特的风险：它会自主推理、自主行动。哪怕部署得再完美，要是一开始没做好安全和责任管控，照样会出问题。所以安全管控得从第一天就融入流程，不能事后补。

传统软件的执行路径是固定的，但智能体会自己做决策——它会解读模糊的请求、访问多个工具、跨会话记信息。这种自主性会带来三类独特风险：

## 1. 提示词注入与恶意操作
恶意用户可能会骗智能体做不该做的事，或者绕过限制。

## 2. 数据泄露
智能体可能会在回复里，或者用工具的时候，不小心把敏感信息泄露出去。

## 3. 记忆污染
要是智能体的记忆里存了错误信息，会影响之后所有的交互。

好在有现成的框架能解决这些问题，比如谷歌的“安全 AI 智能体方案”12（Secure AI Agents approach）和“谷歌安全 AI 框架”（SAIF）13，核心是三层防护：

## 1. 政策定义与系统指令（智能体的“宪法”）
第一步先明确“智能体该做什么、不该做什么”，把这些规则写成“系统指令（SI）”——相当于智能体的核心准则。

## 2. 防护栏、安全措施与过滤（执行层）
这一层是“硬拦截”的执行机制，主要做三件事：
- 输入过滤：用分类器和 Perspective API 这类服务分析用户输入，把恶意请求拦在智能体外面；
- 输出过滤：智能体生成回复后，用 Vertex AI 自带的安全过滤器做最后检查，看有没有有害内容、个人敏感信息（PII）或违反政策的内容。比如回复发给用户前，先过一遍 Vertex AI 自带的安全过滤器14，还能配置成“拦截含特定 PII、有毒语言或其他有害内容的输出”；
- 人在回路（HITL）升级：遇到高风险或模糊的操作，系统会暂停，把问题交给人工审核确认。

## 3. 持续保障与测试
安全不是“一劳永逸”的，得不断评估、不断调整：
- 严格评估：只要改了模型或安全系统，就要重新跑一遍完整的评估流水线（用 Vertex AI 评估工具）；
- 专门的负责任 AI（RAI）测试：针对性测试风险点——可以编专门的数据集，或者用模拟智能体测试，包括“中立视角（NPOV）评估”和“一致性评估”；
- 主动红队测试：主动找漏洞——既可以靠人工创意测试，也能用 AI 模拟不同角色来测试安全系统。

2025年11月  


# 量产阶段的运维工作
智能体上线了，重点就要从“开发”转向一个全新的挑战：当成千上万个用户在用它的时候，怎么保证系统可靠、成本可控、安全无虞？

传统服务的逻辑是固定的，但智能体是“自主行动的角色”——它可能会走意想不到的推理路径，出现“突发行为”，还可能在没人管的情况下产生高额成本。

要管好这种自主性，得用不一样的运维模式：不能只靠静态监测，高效的团队会建立一个“持续循环”——实时监测系统行为（Observe），采取行动维护性能和安全（Act），根据量产经验优化智能体（Evolve）。这个一体化的循环，就是智能体量产运维的核心准则。


## 监测：智能体的“感官系统”
要信任并管理一个自主智能体，首先得懂它的运作过程。“可监测性”就是帮你获取这种洞察的关键，相当于后面“行动（Act）”和“迭代（Evolve）”阶段的“感官系统”。

一套稳健的监测体系要靠三大支柱，三者结合才能完整呈现智能体的行为：
- 日志（Logs）：详细的“行为日记”，记录每一次工具调用、错误和决策；
- 追踪（Traces）：把零散日志串起来的“故事线”，能看出智能体为啥会做某个操作；
- 指标（Metrics）：汇总后的“成绩单”，从宏观上展示性能、成本和运维健康度，告诉你系统跑得好不好。

举个例子，在谷歌云里，这套体系是这么实现的：用户请求会在 Cloud Trace15 里生成一个唯一 ID，这个 ID 会把“Vertex AI Agent Engine9 的调用、模型调用、工具执行”都关联起来，还能看到每个步骤的耗时；详细日志会传到 Cloud Logging16；要是延迟超过阈值，Cloud Monitoring17 的仪表盘会触发警报。而且“智能体开发工具包（ADK）”18 自带 Cloud Trace 集成功能，能自动给智能体的操作加“监测埋点”。

做好这三大支柱，你就能从“摸黑运维”变成“数据驱动的清晰管控”，为智能体的量产运维打下基础。（想深入了解这些概念，可以看《智能体质量：监测、日志、追踪、评估、指标》）

2025年11月  


## 行动：运维调控的“操作杆”
光监测不行动，再好看的仪表盘也只是“花钱买摆设”。“行动（Act）”阶段的核心是“实时干预”——根据监测到的情况，调动各种“操作杆”，管好智能体的性能、成本和安全。

要注意区分“Act”和后面会讲的“Evolve”：“Act”是系统的“自动反应机制”，用来实时维持稳定；而“Evolve”是“战略层面的优化”，靠学习行为来打造更好的系统。

智能体是自主的，你没法提前编好所有情况的应对逻辑，所以得搭一套稳健的机制来影响它的量产行为。这些运维“操作杆”主要分两类：管理系统健康，管理系统风险。


### 管理系统健康：性能、成本与规模
和传统微服务不一样，智能体的负载是动态的，还带“状态记忆”，要管好它的健康，得有专门应对“不确定性”的策略。

#### 1. 为扩容做好设计
核心是“把智能体的逻辑和状态分开”：
- 水平扩容：把智能体设计成“无状态的容器化服务”。因为状态存在外部，任何一个实例都能处理任何请求——这样像 Cloud Run10 或“托管版 Vertex AI Agent Engine 运行时”9 这类 Serverless 平台就能自动扩容；
- 异步处理：遇到耗时任务，用“事件驱动”的模式把工作卸出去。这样智能体能保持响应速度，复杂任务在后台慢慢跑。比如在谷歌云里，服务可以把任务发到 Pub/Sub19，然后触发 Cloud Run 服务做异步处理；
- 外部化状态管理：大语言模型本身是无状态的，所以“把记忆存在外部”是必须的。这里有个关键架构选择：Vertex AI Agent Engine 自带“持久化的会话和记忆服务”；而 Cloud Run 更灵活，能直接和 AlloyDB20 或 Cloud SQL21 这类数据库集成。

#### 2. 平衡相互冲突的目标
扩容过程中，总要在三个目标里找平衡：速度、可靠性、成本。
- 速度（延迟）：想让智能体快，就要设计成“并行处理”，积极做结果缓存，用小而高效的模型处理常规任务；
- 可靠性（应对故障）：智能体得能处理临时故障。比如调用工具失败时，要自动重试（最好用“指数退避”策略，给服务恢复时间）。这就要求工具设计成“可安全重试”（幂等性），避免出现“重复扣费”这类 bug；
- 成本：想省钱，就要缩短提示词长度，用便宜的模型处理简单任务，还可以把请求打包批量发送（批处理）。

2025年11月  


### 管理风险：安全响应操作手册
智能体能自主行动，所以得有一套“快速控制风险”的操作手册。一旦发现威胁，要按“控制风险→排查问题→解决问题”的步骤来：

第一步：立即控制风险。优先级是“止损”，通常用“断路器”——也就是功能开关，马上禁用出问题的工具。

第二步：排查问题。风险控制住后，把可疑请求转到“人在回路（HITL）审核队列”，查清楚漏洞的影响范围和严重程度。

第三步：彻底解决问题。团队要出“修复方案”——比如更新输入过滤器、优化系统提示词，然后通过自动化 CI/CD 流水线部署。这样能确保修复方案经过全面测试，彻底堵住漏洞。


### 迭代：从量产中学习优化
“行动（Act）”阶段是系统的“实时战术反应”，而“迭代（Evolve）”阶段是“长期战略优化”。这个阶段的起点，是分析监测数据里的规律和趋势，然后问一个关键问题：“怎么从根源上解决问题，让它再也不发生？”

也就是说，你要从“被动应对量产故障”转向“主动让智能体更聪明、更高效、更安全”——把“监测（Observe）”阶段收集的原始数据，变成能让智能体“架构、逻辑、行为”持续优化的“干货”。

2025年11月  


# 迭代引擎：自动化量产路径
从量产中发现的洞察，只有能快速落地才有价值。比如你发现30%的用户在某个任务上会失败，但要是团队要花半年才能部署修复方案，那这个发现就没用了。

这时候，你在量产前搭的“自动化 CI/CD 流水线”（第3节讲的）就成了迭代的核心引擎。有了这条流水线，你才能把“监测到问题”到“优化落地”的周期从几周到几个月，缩短到几小时到几天。

不管是优化提示词、加新工具，还是更新安全防护栏，只要你有改进想法，流程都应该是这样的：
1. 提交变更：把改进方案提交到有版本管理的代码仓库；
2. 触发自动化：提交后自动触发 CI/CD 流水线；
3. 严格验证：流水线会跑全套单元测试、安全扫描，还会用更新后的数据集做智能体质量评估；
4. 安全部署：验证通过后，用安全发布策略把改进方案部署到量产环境。

这套自动化流程，能把“迭代”从“慢节奏、高风险的手动项目”，变成“快节奏、可重复、数据驱动的常规操作”。

2025年11月  


# 迭代流程：从洞察到落地优化
具体怎么落地迭代？分三步：
1. 分析量产数据：从量产日志里找用户行为、任务成功率、安全事件的规律；
2. 更新评估数据集：把量产中出现的失败案例，变成未来的测试用例，丰富“黄金数据集”；
3. 优化并部署：提交改进方案，触发自动化流水线——不管是优化提示词、加工具，还是更防护栏，都按这个流程来。

这样就能形成“良性循环”：用户每一次交互，都能让智能体变得更好。


## 迭代循环实战案例
某零售智能体的日志（监测阶段）显示：15%的用户问“类似产品”时会遇到错误。产品团队马上开了高优先级工单，迭代阶段开始：
1. 从量产日志里提取案例，给评估数据集加了一个“会失败的测试用例”；
2. AI 工程师优化了智能体的提示词，还加了一个更稳健的“相似产品搜索工具”；
3. 提交变更后，更新后的评估套件自动跑起来，验证通过；
4. 用金丝雀发布把优化方案部署到量产环境。

整个过程不到48小时，用户的问题就解决了。

2025年11月  


# 安全迭代：量产反馈闭环
虽然在量产前（第3.4节）已经搭好了基础的安全和责任管控框架，但安全工作永远没尽头。安全不是“打勾清单”，而是要不断适应的动态过程——量产环境是最终的“测试场”，从这里获得的洞察，是让智能体抵御真实威胁的关键。

这时候，“监测→行动→迭代（Observe→Act→Evolve）”循环在安全领域就变得特别重要。具体流程是“迭代流程”的延伸：
1. 监测（Observe）：监测和日志系统发现新的威胁——比如出现了能绕过现有过滤器的“新型提示词注入”，或者某个意外交互导致了轻微数据泄露；
2. 行动（Act）：安全响应团队按前面说的方法（第4.2节）控制住风险；
3. 迭代（Evolve）：这是提升长期安全性的关键一步，要把安全洞察反哺到开发流程里：
    - 更新评估数据集：把这次的“提示词注入攻击案例”加到评估套件里，作为永久测试用例；
    - 优化防护栏：提示词工程师或 AI 工程师优化智能体的系统提示词、输入过滤器，或者调整工具使用政策，堵住这个新漏洞；
    - 自动化部署：工程师提交改进方案，触发全套 CI/CD 流水线——更新后的智能体要通过“包含新测试用例的评估套件”验证，然后再部署到量产环境，彻底修复漏洞。

这套流程能形成强大的“反馈闭环”：每一次量产安全事件，都能让智能体变得更坚固、更有韧性——把安全策略从“被动防御”变成“主动持续优化”。

想了解更多“负责任 AI”和“AI 智能体系统安全”的内容，可以看白皮书《谷歌安全 AI 智能体方案》12 和《谷歌安全 AI 框架（SAIF）》13。

2025年11月  


# 突破单智能体运维局限
你已经搞定了“单智能体量产运维”，能快速部署智能体了。但随着公司发展，不同团队用不同框架搭了几十个“专精智能体”——这时候新问题来了：这些智能体没法互相配合。

下一节我们就聊聊，怎么用“标准化协议”把这些“孤立的智能体”变成“能互通的生态系统”——让智能体之间协作，释放更大的价值。

2025年11月  


# A2A 协议：可复用与标准化
你们公司已经搭了几十个专精智能体：客服团队有客服智能体，数据分析团队有预测系统，风险管理团队有 fraud 检测智能体。但问题是，这些智能体没法“说话”——要么是用的框架不一样，要么是属于不同项目，甚至部署在不同云平台上。

这种“孤立状态”特别浪费效率：每个团队都在重复造轮子，关键信息被困在“信息孤岛”里。你需要的是“互操作性”——不管是谁搭的智能体、用的什么框架，都能调用其他智能体的能力。

要解决这个问题，得靠“标准化”，具体要用到两个互补的协议：

之前在《智能体工具与 MCP 互操作性》里详细讲过的“模型上下文协议（MCP22）”，是工具集成的通用标准，但它对付不了“智能体之间复杂、带状态的协作”。而“Agent2Agent（A2A23）协议”（现在由 Linux 基金会管理）就是专门解决这个问题的。

两者的区别很关键：
- 要是你需要“简单、无状态的功能”——比如查天气、查数据库，那用 MCP 调用工具就够了；
- 要是你需要“委托复杂任务”——比如“分析上季度客户流失原因，给三个干预方案”，那就要找“能推理、能规划、能自主行动”的智能体，这时候就得用 A2A 协议。

简单说：MCP 是“让你做这件具体的事”，A2A 是“帮你实现这个复杂目标”。

2025年11月  


# A2A 协议：从概念到落地
A2A 协议的核心是“打破部门壁垒，让智能体之间无缝协作”。举个例子：fraud 检测智能体发现了可疑交易，要了解完整背景，就需要调用“交易分析智能体”的数据。要是没有 A2A，就得靠人工分析师手动传数据，可能要花好几个小时；有了 A2A，智能体之间能自动协作，几分钟就能解决问题。

智能体协作的第一步，是“找到能委托任务的伙伴”——这就要靠“智能体卡片（Agent Cards）”24。它是标准化的 JSON 格式，相当于智能体的“名片”，会写清楚“这个智能体能做什么、需要什么安全权限、有哪些技能、怎么联系它（url）”——这样生态里的任何智能体，都能动态找到其他伙伴。

下面是个“智能体卡片”的例子：

（代码片段1：check_prime_agent 智能体的示例卡片，Python 格式）
```python
{
    "name": "check_prime_agent",  # 智能体名称
    "version": "1.0.0",  # 版本号
    "description": "An agent specialized in checking whether numbers are prime",  # 描述：专精于判断数字是否为质数的智能体
    "securitySchemes": {
        "agent_oauth_2_0": {  # 安全方案：OAuth 2.0
            "type": "oauth2"
        }
    },
    "defaultInputModes": ["text/plain"],  # 默认输入格式：纯文本
    "defaultOutputModes": ["application/json"],  # 默认输出格式：JSON
    "skills": [  # 技能列表
        {
            "id": "prime_checking",  # 技能ID
            "name": "Prime Number Checking",  # 技能名称：质数判断
            "description": "Check if numbers are prime using efficient algorithms",  # 描述：用高效算法判断数字是否为质数
            "tags": ["mathematical", "computation", "prime"]  # 标签：数学、计算、质数
        }
    ],
    "url": "http://localhost:8001/a2a/check_prime_agent"  # 智能体访问地址
}
```

要用上这个协议，不用彻底重构现有架构——像 ADK 这样的框架能帮你省很多事（查看文档25）。只要调用一个函数，就能让现有智能体支持 A2A 协议：它会自动生成“智能体卡片”，还能把智能体接入网络。

（代码片段2：用 ADK 的 to_a2a 工具包装现有智能体，实现 A2A 通信，Python 格式）
```python
# 示例：用 ADK 让智能体支持 A2A 协议
from google.adk.a2a.utils.agent_to_a2a import to_a2a

# 你现有的智能体
root_agent = Agent(
    name='hello_world_agent',  # 智能体名称
    # ... 这里是你的智能体代码 ...
)

# 让智能体支持 A2A 协议
a2a_app = to_a2a(root_agent, port=8001)  # 端口设为 8001

# 用 uvicorn 启动服务
# uvicorn agent:a2a_app --host localhost --port 8001

# 或者用 Agent Engine 启动
# from vertexai.preview.reasoning_engines import A2aAgent
# from google.adk.a2a.executor.a2a_agent_executor import A2aAgentExecutor
# a2a_agent = A2aAgent(
#     agent_executor_builder=lambda: A2aAgentExecutor(agent=root_agent)
# )
```

智能体“上线”后，其他智能体只要引用它的“智能体卡片”，就能调用它的能力。比如客服智能体现在能调用远程的“产品目录智能体”，而且不用知道对方的内部逻辑。

（代码片段3：用 ADK 的 RemoteA2aAgent 类连接并调用远程智能体，Python 格式）
```python
# 示例：用 ADK 调用远程 A2A 智能体
from google.adk.agents.remote_a2a_agent import RemoteA2aAgent

# 初始化质数判断智能体（远程）
prime_agent = RemoteA2aAgent(
    name="prime_agent",  # 智能体名称
    description="Agent that handles checking if numbers are prime.",  # 描述：处理质数判断的智能体
    # 智能体卡片地址：从这个地址获取远程智能体的“名片”
    agent_card="http://localhost:8001/a2a/check_prime_agent/.well-known/agent-card.json"
)
```

这还能实现“分层组合”的强大能力：你可以搭一个“主智能体”，让它同时调度“本地子智能体”（处理简单任务）和“远程专精智能体”（通过 A2A 调用），打造更强大的系统。

（代码片段4：在 ADK 中，把远程 A2A 智能体（prime_agent）作为子智能体，搭建分层智能体结构，Python 格式）
```python
# 示例：用 ADK 搭建分层智能体
# 1. 本地子智能体：处理掷骰子任务
roll_agent = Agent(
    name="roll_agent",  # 智能体名称
    instruction="You are an expert at rolling dice."  # 指令：你是掷骰子专家
)

# 2. 远程 A2A 智能体：处理质数判断
prime_agent = RemoteA2aAgent(
    name="prime_agent",  # 智能体名称
    # 智能体卡片地址
    agent_card="http://localhost:8001/.well-known/agent-card.json"
)

# 3. 主智能体：整合两个子智能体
root_agent = Agent(
    name="root_agent",  # 主智能体名称
    # 指令：掷骰子任务交给 roll_agent，质数判断交给 prime_agent
    instruction="""Delegate rolling dice to roll_agent, prime checking to prime_agent.""",
    sub_agents=[roll_agent, prime_agent]  # 子智能体列表
)
```

不过，要实现这种“自主协作”，有两个技术要求是绝对不能少的：
1. 分布式追踪：每个请求都要有唯一的追踪 ID，这样才能跨多个智能体调试，还能保留完整的审计记录；
2. 稳健的状态管理：A2A 交互天生是“带状态”的，需要复杂的存储层来跟踪进度，确保交互的“事务完整性”（比如不会出现“一半成功、一半失败”的情况）。

A2A 最适合用在“跨团队的正式集成”场景——需要稳定的服务协议。如果是“单个应用内的紧密耦合任务”，用轻量级的本地子智能体通常更高效。

随着生态成熟，新智能体应该“天生支持这两种协议”（A2A 和 MCP），确保每个新组件都能马上被发现、能互通、能复用，让整个系统的价值不断叠加。

2025年11月  


# A2A 与 MCP 如何协同工作
（图4：A2A 与 MCP 协同工作示意图：1. 用户与路由智能体交互；2. 路由智能体调用“智能体注册中心”里的专精智能体（通过 A2A 协议）；3. 专精智能体调用“工具注册中心”里的工具（通过 MCP 协议））

A2A 和 MCP 不是竞争关系，而是互补的协议——适用的抽象层级不一样：
- MCP 管的是“工具和资源”：比如计算器、数据库 API 这类“ primitive（基础组件）”，输入输出都是结构化的、定义明确的；
- A2A 管的是“其他智能体”：也就是能推理、能规划、会用多个工具、能记状态，还能完成复杂目标的自主系统。

最强大的智能体系统，会用“分层架构”把这两种协议结合起来：应用层面主要用 A2A 协议，让多个智能体协同完成高级任务；而每个智能体内部，会用 MCP 协议调用自己专属的工具和资源。

举个“自动驾驶维修店”的例子（店里的员工都是自主 AI 智能体），就能看明白两者怎么配合：
1. 用户→智能体（A2A）：客户用 A2A 协议和“店长智能体”沟通，描述一个高级需求：“我的车有异响”；
2. 智能体→智能体（A2A）：店长智能体先和客户多轮沟通排查问题，然后用 A2A 协议把任务委托给“维修师智能体”；
3. 智能体→工具（MCP）：维修师智能体要做具体操作，就用 MCP 协议调用专属工具：比如用 diagnostic scanner（诊断扫描仪）跑 scan_vehicle_for_error_codes()（扫描车辆故障码）、查维修手册数据库调用 get_repair_procedure()（获取维修步骤）、操作平台升降机调用 raise_platform()（升起平台）；
4. 智能体→智能体（A2A）：维修师智能体诊断后发现需要换零件，就用 A2A 协议和外部的“零件供应商智能体”沟通，查库存、下订单。

在这个流程里：
- A2A 负责“高层级、带对话的任务协作”——比如客户和店长、店长和维修师、维修师和供应商之间的交互；
- MCP 负责“标准化的底层连接”——帮维修师智能体可靠地调用具体工具，完成实际操作。

2025年11月  


# 注册中心架构：何时建、怎么建
为啥有的公司要建“注册中心”，有的公司却不用？答案要看“规模和复杂度”：
- 要是只有50个工具，手动配置还能应付；
- 要是工具超过5000个，还分散在不同团队、不同环境里，就会遇到“找不到工具”的问题，这时候就必须用系统化方案解决了。


## 工具注册中心（Tool Registry）
工具注册中心用 MCP 这类协议来“ catalog（编目）”所有资源——不管是函数还是 API。它不会让智能体直接访问几千个工具，而是会编“精选列表”，常见的用法有三种：
- 通用智能体：能访问完整工具目录，优点是覆盖范围广，缺点是速度慢、准确率低；
- 专精智能体：只用预设的工具子集，优点是性能高；
- 动态智能体：运行时才查注册中心，能适应新工具。

工具注册中心最大的价值是“方便人找工具”：开发人员先查有没有现成工具，避免重复开发；安全团队能审计工具访问权限；产品负责人能清楚知道智能体有哪些能力。


## 智能体注册中心（Agent Registry）
智能体注册中心和工具注册中心思路一样，不过是用 A2A 的“智能体卡片”（Agent Cards）来编目智能体。它能帮团队找到、复用已有的智能体，减少重复开发，还能为“智能体自动委托任务”打基础（不过这个场景还在发展中）。


## 注册中心的权衡与决策框架
注册中心能提供“发现能力”和“管控能力”，但代价是“需要维护”。建议先不用建，等生态规模到了“需要中心化管理”的时候再建！

### 决策框架：
- 工具注册中心：当“找工具”变成瓶颈，或者安全要求“中心化审计”时，再建；
- 智能体注册中心：当多个团队需要“找、复用专精智能体”，又不想搞“紧耦合”时，再建。

2025年11月  


# 整合落地：AgentOps 生命周期
现在我们可以把前面讲的这些支柱，整合起来变成一套完整的参考架构了！

整个生命周期从“开发人员的内部循环”开始——这个阶段主要是快速本地测试和原型开发，确定智能体的核心逻辑；然后进入“正式的量产前流程”：自动化评估会当好“守门人”，验证智能体的质量和安全性（对照黄金数据集）；接着用“安全发布策略”把智能体推到量产环境；最后靠“全方位监测”收集真实世界的数据，为“持续迭代循环”提供燃料——让每一个洞察都能变成下一次的优化。

想全面了解“AI 智能体落地运维”的细节（包括评估、工具管理、CI/CD 标准化、高效架构设计），可以去谷歌云官方 YouTube 频道看视频《AgentOps：AI 智能体落地运维》26。

（图5：AgentOps 的核心能力、环境与流程：包括数据湖/数据网格环境、开发环境、预发布环境、量产环境，涉及数据治理、基础设施、智能体评估、AI 安全、CI/CD 流水线、注册中心等模块）

2025年11月  


# 结语：用 AgentOps 打通量产“最后一公里”
把 AI 原型变成量产系统，不只是技术升级，更是组织层面的变革——需要一套全新的运维规范：AgentOps。

大多数智能体项目栽在“最后一公里”，不是因为技术不行，而是低估了“自主系统的运维复杂度”。这份指南就帮你搭好了跨越鸿沟的路径：
1. 先打好“人员与流程”的基础，做好管控；
2. 再用“量产前策略”（评估守门、合格再部署）把高风险的发布自动化；
3. 智能体上线后，靠“监测→行动→迭代（Observe→Act→Evolve）”循环，让每一次用户交互都变成优化的机会；
4. 最后用“互操作性协议”（A2A、MCP）实现规模化——把孤立的智能体变成能协作的智能生态。

短期来看，AgentOps 能帮你规避安全漏洞、实现快速回滚，这些收益已经值得投入；但长期的核心价值是“速度”——成熟的 AgentOps 能让团队把“优化落地”的周期从几周缩短到几小时，让智能体从“静态部署”变成“持续进化的产品”。


## 下一步行动建议
- 如果你刚起步：先抓基础——编第一版评估数据集、搭 CI/CD 流水线、做好全方位监测。“智能体 starter 包”是个好起点，几分钟就能搭好量产就绪的智能体项目，基础功能都帮你内置好了；
- 如果你在规模化：升级你的运维体系——把“量产洞察→落地优化”的反馈 loop 自动化，用标准化互操作协议（A2A、MCP）搭“协同生态”，而不是一个个孤立的解决方案。

AI 的下一个前沿，不只是“把单个智能体做得更好”，而是“搭建能学习、能协作的多智能体系统”——而 AgentOps 就是实现这个目标的基础。

希望这份操作手册能帮你打造出下一代“智能、可靠、可信”的 AI 系统。记住：打通量产“最后一公里”不是项目的终点，而是创造价值的起点！

2025年11月  


# 附注
1. https://github.com/GoogleCloudPlatform/agent-starter-pack（谷歌云平台智能体 starter 包）
2. https://cloud.google.com/vertex-ai/docs/evaluation/introduction（Vertex AI 评估工具介绍）
3. https://github.com/GoogleCloudPlatform/agent-starter-pack/blob/example-agent/example-agent/.cloudbuild/pr_checks.yaml（PR 检查配置模板）
4. https://cloud.google.com/build（Cloud Build 工具）
5. https://github.com/GoogleCloudPlatform/agent-starter-pack/blob/example-agent/example-agent/.cloudbuild/staging.yaml（预发布部署模板）
6. https://github.com/GoogleCloudPlatform/agent-starter-pack/blob/example-agent/example-agent/.cloudbuild/deploy-to-prod.yaml（量产部署模板）
7. https://github.com/GoogleCloudPlatform/agent-starter-pack/blob/example-agent/example-agent/terraform（Terraform 配置模板）
8. https://cloud.google.com/secret-manager（Secret Manager 密钥管理服务）
9. https://cloud.google.com/agent-builder/agent-engine/overview（Agent Engine 智能体引擎）
10. https://cloud.google.com/run（Cloud Run 容器化服务）
11. https://cloud.google.com/load-balancing/docs/https/traffic-management（Cloud Load Balancing 流量管理）
12. https://research.google/pubs/an-introduction-to-googles-approach-for-secure-ai-agents/（谷歌安全 AI 智能体方案介绍）
13. https://safety.google/cybersecurity-advancements/saif/（谷歌安全 AI 框架 SAIF）
14. https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes（Vertex AI 安全过滤器配置）
15. https://cloud.google.com/trace（Cloud Trace 追踪工具）
16. https://cloud.google.com/logging（Cloud Logging 日志工具）
17. https://cloud.google.com/monitoring（Cloud Monitoring 监测工具）
18. https://google.github.io/adk-docs/observability/cloud-trace/（ADK Cloud Trace 集成文档）
19. https://cloud.google.com/pubsub（Pub/Sub 消息队列服务）
20. https://cloud.google.com/alloydb（AlloyDB 数据库）
21. https://cloud.google.com/sql（Cloud SQL 数据库）
22. https://modelcontextprotocol.io/（模型上下文协议 MCP）
23. https://a2a-protocol.org/latest/specification/（A2A 协议最新规范）
24. https://a2a-protocol.org/latest/specification/#5-agent-discovery-the-agent-card（A2A 协议：智能体发现与智能体卡片）
25. https://google.github.io/adk-docs/a2a/（ADK A2A 协议文档）
26. https://www.youtube.com/watch?v=kJRgj58ujEk（视频《AgentOps：AI 智能体落地运维》）

2025年11月